{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for OR and FE\n",
    "## Wealth Management Project 6: Real Time Impacts & Stress Testing\n",
    "\n",
    "### *Group 27: Louis Francois, \tQinyi Li, Parag Dilip Mahajan*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9I0N2CfxaTg0",
    "outputId": "26b28854-b633-44d1-e06f-490e80a8533d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCopyright:\\n    Copyright (C) 2020 Sauma Capital Inc - All Rights Reserved\\n    Unauthorized copying of this file, via any medium, is strictly prohibited\\n    Proprietary and confidential\\nProduct: Scenarios based stress test\\nAuther: Kai Fang\\nDescription: Risk Scenarios analysis to generate risk shock for portfoliio of mutual fund/other asset\\n            The framework contains mutliple parts:\\n            1) Risk Generator\\n            2) Risk Scenarios\\n            3) Risk Simulator\\n            This file currently only provide based class for the researcher/developer to inherit, and provide an interface\\n            to enforce the format of the programming prastice\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copyright:\n",
    "    Copyright (C) 2020 Sauma Capital Inc - All Rights Reserved\n",
    "    Unauthorized copying of this file, via any medium, is strictly prohibited\n",
    "    Proprietary and confidential\n",
    "Product: Scenarios based stress test\n",
    "Auther: Kai Fang\n",
    "Description: Risk Scenarios analysis to generate risk shock for portfoliio of mutual fund/other asset\n",
    "            The framework contains mutliple parts:\n",
    "            1) Risk Generator\n",
    "            2) Risk Scenarios\n",
    "            3) Risk Simulator\n",
    "            This file currently only provide based class for the researcher/developer to inherit, and provide an interface\n",
    "            to enforce the format of the programming prastice\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "uG4zcsRcnzGR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import sauma.core \n",
    "import pymysql\n",
    "import json\n",
    "from sqlalchemy import select, insert\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from functools import partial, reduce   \n",
    "import logging\n",
    "from utils import *\n",
    "from DatabaseDevelopment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk factor generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "saGp_BjtaTg-"
   },
   "outputs": [],
   "source": [
    "class RiskGeneratorBased:\n",
    "    \"\"\"Risk Generator Based class that risk generator should inherit. For example, you could create a multi-variable regression\n",
    "        Based risk generator, to map the risk factors to an asset or portfolio, and do the training to generate model parameters:\n",
    "        beta, that we would possible cached in database or output to flat file. The input dependent variable would be a two dimension\n",
    "        matrix (time, asset return/price) and the dependent variable would be two dimension matrix (time, risk factor series)\n",
    "        For example:\n",
    "        Y: [[Date, Asset1, Asset2, Asset3, Asset4, Asset5 ...],\n",
    "            [.....],\n",
    "            [.....],\n",
    "            ...]\n",
    "        X: [[Date, Factor1, Factor2, Factor3, Factor4, ....],\n",
    "            [.....],\n",
    "            [.....],\n",
    "            ....]\n",
    "        Final Result of output would be:\n",
    "        [[Factor,  Asset1, Asset2, Asset3, Asset4, Asset5 ...],\n",
    "         [Factor1, .....],\n",
    "         [Factor2, .....],\n",
    "         [Factor3, .....],\n",
    "         .....]\n",
    "        Currently we assume linear relationship of the risk factor, but later when we have some non-linear relationship, could have different\n",
    "        return format.\n",
    "        If you have mutliple asset, this may include mutliple traning process.\n",
    "    \"\"\"\n",
    "    def __init__(self, risk_generator_name):\n",
    "        self._risk_generator_name = risk_generator_name\n",
    "    \n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement set_up function!\")\n",
    "    \n",
    "    def risk_factors(self):\n",
    "        \"\"\"Print the list of risk factors that you use in this generator, do not hard coded the return list, the information\n",
    "        should be able to be gathered from private variables either from set_up function or load data function\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement risk_factors function!\")\n",
    "    \n",
    "    def risk_generator_name(self):\n",
    "        \"\"\"This provide identifier of the clustering strategy that you are implementing.\"\"\"\n",
    "        return self._risk_generator_name\n",
    "    \n",
    "    def machine_learning_based(self):\n",
    "        \"\"\"This method tells us whether the risk_generator category is machine learning \n",
    "            based and need to run fit to train model parameters or not\n",
    "            \n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                bool\n",
    "                True if the strategy need to run fit to be ready for prediction, otherwise No\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement machine_learning_based!\")\n",
    "    \n",
    "    def load_raw_data(self, source_type, **kwargs):\n",
    "        \"\"\"Function to load raw data from source, should be able to support \n",
    "        reading data from flat file or sql database. Please just implement the one using flat file now,\n",
    "        later we would provide the sql python package that we would want to utilize for the database task\n",
    "        You may also want to have some data cleaning on the raw data, please define private method for data transformation.\n",
    "        and the data should be saved as private variable, as it would be used for later training and testing process.\n",
    "        \n",
    "        Parameters:\n",
    "            source_type: str\n",
    "                flat file type or sql, if it is flat file, file directory or \n",
    "                path need to be passed in as argument or in the setup function\n",
    "                If it is sql, connection need to be extablished in setup function\n",
    "                please avoid any hard coded name in the class, and set global variable to define those file name\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement load_raw_data function!\")\n",
    "    \n",
    "    def set_hyper_parameter(self, **kwargs):\n",
    "        \"\"\"Function to re_config any hyper parameters that you need for your model, \n",
    "        the parameters should be initialized in your inherited setup function, by reading the config\n",
    "        either from a config file or from argument, but please enable user to have a config file to set\n",
    "        these hyper-parameters.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement set_hyper_parameter!\")\n",
    "\n",
    "    def print_hyper_parameter(self, **kwargs):\n",
    "        \"\"\"Print all the hyper parameters that you set for your model.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement print_hyper_parameter!\")\n",
    "    \n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Function to execute training either based on the data that you load from file or passed in as argument.\n",
    "        When X, Y are passed in as argument, would train the model based on the training dataset passed in, and over write\n",
    "        the existing data cached in the risk generator obj. If you implement some new machine learning model rather than using\n",
    "        existing machine learning model by some python package, please seperate the implementation of the model in another class,\n",
    "        and initialize an instance of that model in your setup function rather than implement the model directly in the fit function,\n",
    "        so that we could seprate the business logics with the machine learning model maintaining logics, and those model could be reused\n",
    "        somewhere else too.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement print_hyper_parameter!\")\n",
    "    \n",
    "    def predict(self, **kwargs):\n",
    "        \"\"\"Run prediction after fitting the model, should throw error message when the model did not run fit yet.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement predict\")\n",
    "    \n",
    "    def model_summary(self):\n",
    "        \"\"\"Function that provide summary of model result: prediction accuracy, different matrix \n",
    "            to measure the model, and hyper-parameters of the model\"\n",
    "\n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                dict {str: float/dataframe}\n",
    "                key is the staticial measure name\n",
    "                value is the statical measure, either a number or a matrix or a dataframe\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement model_summary\")\n",
    "\n",
    "    def output_result(self, **kwargs):\n",
    "        \"\"\"Function to output the model, could use pickle to cached the obj that \n",
    "        has been trained, so that you could load the obj later directly later, and you could also use this function\n",
    "        to output the beta output of the risk generator, please use arguments to config what you want to output\n",
    "        \n",
    "        Parameters:\n",
    "            output_model: bool\n",
    "                output model to pickle container\n",
    "            output_beta: bool\n",
    "                output beta of each risk factors for each fund\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement output_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "2JAfzEafaThF"
   },
   "outputs": [],
   "source": [
    "# Define a Multi-Regression Based risk factor generator by inheriting from the class above.\n",
    "# if you have some generic method that all risk factor generator could use, like those method in define in the based class, you could directly\n",
    "# edit the based class, but for method that is specific to the method that you use in your risk factor generation, you should do it in the derived class\n",
    "\n",
    "\n",
    "class SimpleRegressionRiskGenerator(RiskGeneratorBased):\n",
    "    def __init__(self, risk_generator_name, risk_factors): \n",
    "        self._risk_generator_name = risk_generator_name\n",
    "        self._risk_factors = risk_factors # list of risk factors (strings)\n",
    "    \n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator\"\"\"\n",
    "        self._hyperparameters = kwargs.get('hyperparameters') # dict: {'hyperparameter1': value1, ...}\n",
    "        self._data_path = kwargs.get('data_path') # dict: {'fund': data_path for fund data, 'index': data_path for index data}\n",
    "    \n",
    "    def risk_factors(self):\n",
    "        \"\"\"Print the list of risk factors that you use in this generator, do not hard coded the return list, the information\n",
    "        should be able to be gathered from private variables either from set_up function or load data function\"\"\"\n",
    "        print(self._risk_factors)\n",
    "    \n",
    "    def risk_generator_name(self):\n",
    "        \"\"\"This provide identifier of the clustering strategy that you are implementing.\"\"\"\n",
    "        return self._risk_generator_name\n",
    "    \n",
    "    def machine_learning_based(self):\n",
    "        \"\"\"This method tells us whether the risk_generator category is machine learning \n",
    "            based and need to run fit to train model parameters or not\n",
    "            \n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                bool\n",
    "                True if the strategy need to run fit to be ready for prediction, otherwise No\n",
    "        \"\"\"\n",
    "        return True \n",
    "    \n",
    "    def load_raw_data(self, **kwargs):\n",
    "        \"\"\"Function to load raw data from source, should be able to support \n",
    "        reading data from flat file or sql database. Please just implement the one using flat file now,\n",
    "        later we would provide the sql python package that we would want to utilize for the database task\n",
    "        You may also want to have some data cleaning on the raw data, please define private method for data transformation.\n",
    "        and the data should be saved as private variable, as it would be used for later training and testing process.\n",
    "        \n",
    "        Parameters:\n",
    "            source_type: str\n",
    "                flat file type or sql, if it is flat file, file directory or \n",
    "                path need to be passed in as argument or in the setup function\n",
    "                If it is sql, connection need to be extablished in setup function\n",
    "                please avoid any hard coded name in the class, and set global variable to define those file name\n",
    "        \"\"\"\n",
    "        self._factors_data = pd.read_csv(self._data_path.get('index'))\n",
    "        self._assets_data = pd.read_csv(self._data_path.get('fund'))\n",
    "        self._libor_data = pd.read_csv(self._data_path.get('libor'))\n",
    "        \n",
    "    def split_train_test_data(self, **kwargs):\n",
    "        X, Y = self._factors_data, self._assets_data\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=kwargs.get('test_size'), random_state=42)\n",
    "        self._X_train = X_train.values[:,1:] # convert to numpy array and get rid of dates\n",
    "        self._X_test = X_test.values[:,1:]\n",
    "        self._Y_train = Y_train.values[:,1:]\n",
    "        self._Y_test = Y_test.values[:,1:]\n",
    "    \n",
    "    def set_hyper_parameter(self, **kwargs):\n",
    "        \"\"\"Function to re_config any hyper parameters that you need for your model, \n",
    "        the parameters should be initialized in your inherited setup function, by reading the config\n",
    "        either from a config file or from argument, but please enable user to have a config file to set\n",
    "        these hyper-parameters.\"\"\"\n",
    "        path = kwargs.get('config_path') # string\n",
    "        with open(path) as f:\n",
    "            config = yaml.load(f, Loader=yaml.BaseLoader)  # config is a dict\n",
    "        self._hyperparameters = config\n",
    "        \n",
    "    def print_hyper_parameter(self, **kwargs):\n",
    "        \"\"\"Print all the hyper parameters that you set for your model.\"\"\"\n",
    "        print(self._hyperparameters)\n",
    "    \n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Function to execute training either based on the data that you load from file or passed in as argument.\n",
    "        When X, Y are passed in as argument, would train the model based on the training dataset passed in, and over write\n",
    "        the existing data cached in the risk generator obj. If you implement some new machine learning model rather than using\n",
    "        existing machine learning model by some python package, please seperate the implementation of the model in another class,\n",
    "        and initialize an instance of that model in your setup function rather than implement the model directly in the fit function,\n",
    "        so that we could seprate the business logics with the machine learning model maintaining logics, and those model could be reused\n",
    "        somewhere else too.\"\"\"\n",
    "        self._model = {} # dict to store all the regression models (one for each asset/fund)\n",
    "        for i in range(self._Y_train.shape[1]):\n",
    "            reg = LinearRegression(fit_intercept=False) \n",
    "            reg.fit(self._X_train,self._Y_train[:,i])\n",
    "            self._model['fund'+str(i+1)] = reg\n",
    "    \n",
    "    def predict(self, **kwargs):\n",
    "        \"\"\"Run prediction after fitting the model, should throw error message when the model did not run fit yet.\"\"\"\n",
    "        assert (hasattr(self, '_model')), 'Did not run fit yet'\n",
    "        self._Y_pred = {}\n",
    "        for fund, model in self._model.items():\n",
    "            self._Y_pred[fund] = model.predict(self._X_test)\n",
    "           \n",
    "    def betas_fund(self, **kwargs):\n",
    "        \"\"\"For each fund, store list of betas obtained\"\"\"\n",
    "        betas = {}\n",
    "        for fund, model in self._model.items():\n",
    "            betas[fund] = model.coef_\n",
    "        self._betas_fund = betas\n",
    "        return self._betas_fund\n",
    "    \n",
    "    def betas_output(self, **kwargs):\n",
    "        \"\"\"Create and print a matrix such that each row corresponds to a risk factor, with the name of the risk factor followed \n",
    "        by all the betas obtained for each fund, i.e. we want the following output:\n",
    "        [[Factor,  Asset1, Asset2, Asset3, Asset4, Asset5 ...],\n",
    "         [Factor1, .....],\n",
    "         [Factor2, .....],\n",
    "         [Factor3, .....],\n",
    "         .....]\"\"\"\n",
    "        betas_output = []\n",
    "        for beta in self._betas_fund.values():\n",
    "            if len(betas_output) == 0:\n",
    "                betas_output = beta\n",
    "            else: \n",
    "                betas_output = np.vstack((betas_output, beta))\n",
    "        betas_output = np.concatenate((np.array(self._risk_factors).reshape(len(self._risk_factors),1), betas_output.T), axis = 1)\n",
    "        self._betas_output = betas_output\n",
    "        return self._betas_output \n",
    "    \n",
    "    def get_momentum_factor_score(self):\n",
    "        self.mom_score = {} #Dict from funds to vol scores for each factor\n",
    "        funds_data = self._assets_data.copy()\n",
    "        funds_data.set_index('Date',inplace=True)\n",
    "        log_funds_returns = funds_data.apply(lambda x: np.log(1+x/100) if np.issubdtype(x.dtype, np.number) else x)\n",
    "\n",
    "        libor_data = self._libor_data.copy()\n",
    "        libor_data.set_index('Date',inplace=True)\n",
    "        libor_data.dropna(inplace=True)\n",
    "        libor_data = libor_data.iloc[::-1]\n",
    "        libor_returns = libor_data.pct_change()[1:]\n",
    "        libor_returns = libor_returns.iloc[::-1]\n",
    "        log_libor_returns = libor_returns.apply(lambda x: np.log(1+x) if np.issubdtype(x.dtype, np.number) else x)\n",
    "        \n",
    "        mom_factor_scores = log_funds_returns.sub(log_libor_returns['USD LIBOR 3M '],axis=0)\n",
    "        \n",
    "        self.mom_score = mom_factor_scores[30:365].sum().to_dict()\n",
    "    \n",
    "    def get_vol_factor_score(self):\n",
    "        self.vol_score = {} #Dict from funds to vol scores for each factor\n",
    "        funds_data = self._assets_data.copy()\n",
    "        funds_data.set_index('Date',inplace=True)\n",
    "        log_funds_returns = funds_data.apply(lambda x: np.log(1+x/100) if np.issubdtype(x.dtype, np.number) else x)\n",
    "\n",
    "        libor_data = self._libor_data.copy()\n",
    "        libor_data.set_index('Date',inplace=True)\n",
    "        libor_data.dropna(inplace=True)\n",
    "        libor_data = libor_data.iloc[::-1]\n",
    "        libor_returns = libor_data.pct_change()[1:]\n",
    "        libor_returns = libor_returns.iloc[::-1]\n",
    "        log_libor_returns = libor_returns.apply(lambda x: np.log(1+x) if np.issubdtype(x.dtype, np.number) else x)\n",
    "        \n",
    "        vol_factor_scores = log_funds_returns.sub(log_libor_returns['USD LIBOR 3M '],axis=0)\n",
    "        \n",
    "        self.vol_score = vol_factor_scores[30:365].max().sub(vol_factor_scores[30:365].min()).to_dict()\n",
    "        \n",
    "    def get_size_factor_score(self,Mv_data_path):\n",
    "        MV_data = pd.read_csv(Mv_data_path)\n",
    "        MV_data.set_index('Date',inplace = True)\n",
    "        MV_data = MV_data.astype(float)\n",
    "        MV_data.reset_index(drop=True, inplace=True)\n",
    "        MV_data = MV_data.apply(lambda x: -np.log(x))\n",
    "        self.size_score = MV_data.sum().to_dict()\n",
    "                \n",
    "        \n",
    "    def select_top_n_funds_with_factor_score(self,n,factor_score_dict):\n",
    "        top_n_funds = sorted(factor_score_dict,key=factor_score_dict.get,reverse=True)[:n]\n",
    "        self._assets_data = self._assets_data[top_n_funds]\n",
    "          \n",
    "    def model_summary(self):\n",
    "        \"\"\"Function that provide summary of model result: prediction accuracy, different matrix \n",
    "            to measure the model, and hyper-parameters of the model\"\n",
    "\n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                dict {str: float/dataframe}\n",
    "                key is the staticial measure name\n",
    "                value is the statical measure, either a number or a matrix or a dataframe\n",
    "        \"\"\"\n",
    "        ### can add other performance measures later on \n",
    "        summary = dict()\n",
    "        summary['rmse score'] = {}\n",
    "        i = 0\n",
    "        for fund in self._model.keys():\n",
    "            mse = mean_squared_error(y_true = self._Y_test[:,i], y_pred = self._Y_pred[fund])\n",
    "            rmse = math.sqrt(mse)\n",
    "            summary['rmse score'][fund] = rmse\n",
    "            i += 1  \n",
    "        return summary \n",
    "\n",
    "    def output_result(self, **kwargs):\n",
    "        \"\"\"Function to output the model, could use pickle to cached the obj that \n",
    "        has been trained, so that you could load the obj later directly later, and you could also use this function\n",
    "        to output the beta output of the risk generator, please use arguments to config what you want to output\n",
    "        \n",
    "        Parameters:\n",
    "            output_model: bool\n",
    "                output model to pickle container\n",
    "            output_beta: bool\n",
    "                output beta of each risk factors for each fund\n",
    "        \"\"\"\n",
    "        save_path = kwargs.get('save_path') # string\n",
    "        output_model = kwargs.get('output_model')\n",
    "        output_beta = kwargs.get('output_beta')\n",
    "        if output_model == True:\n",
    "            f1 = open(save_path + '/model.txt','wb')\n",
    "            pickle.dump(self._model, f1)\n",
    "        if output_beta == True:\n",
    "            f2 = open(save_path + '/beta.txt','wb')\n",
    "            pickle.dump(self._betas_output, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Risk Generator based on Lasso regression and Ridge Regression to do a little bit more risk factor \n",
    "# filtering, by implementing all these derived class, you could diagnose which method are common method that you could define \n",
    "# and move to the base class.\n",
    "class LassoRegressionRiskGenerator(SimpleRegressionRiskGenerator):\n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Function to execute training either based on the data that you load from file or passed in as argument.\n",
    "        When X, Y are passed in as argument, would train the model based on the training dataset passed in, and over write\n",
    "        the existing data cached in the risk generator obj. If you implement some new machine learning model rather than using\n",
    "        existing machine learning model by some python package, please seperate the implementation of the model in another class,\n",
    "        and initialize an instance of that model in your setup function rather than implement the model directly in the fit function,\n",
    "        so that we could seprate the business logics with the machine learning model maintaining logics, and those model could be reused\n",
    "        somewhere else too.\"\"\"\n",
    "        self._model = {} # dict to store all the regression models (one for each asset/fund)\n",
    "        alpha = self._hyperparameters.get('alpha')\n",
    "        max_iter = self._hyperparameters.get('max_iter')\n",
    "        for i in range(self._Y_train.shape[1]):\n",
    "            lasso = Lasso(alpha = alpha, max_iter = max_iter, fit_intercept=False)\n",
    "            lasso.fit(self._X_train,self._Y_train[:,i])\n",
    "            self._model['fund'+str(i+1)] = lasso\n",
    "    \n",
    "    def model_summary(self):\n",
    "        \"\"\"Function that provide summary of model result: prediction accuracy, different matrix \n",
    "            to measure the model, and hyper-parameters of the model\"\n",
    "\n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                dict {str: float/dataframe}\n",
    "                key is the staticial measure name\n",
    "                value is the statical measure, either a number or a matrix or a dataframe\n",
    "        \"\"\"\n",
    "        ### can add other performance measures later on \n",
    "        summary = dict()\n",
    "        summary['hyperparameter'] = self._hyperparameters\n",
    "        summary['rmse score'] = {}\n",
    "        i = 0\n",
    "        for fund in self._model.keys():\n",
    "            mse = mean_squared_error(y_true = self._Y_test[:,i], y_pred = self._Y_pred[fund])\n",
    "            rmse = math.sqrt(mse)\n",
    "            summary['rmse score'][fund] = rmse\n",
    "            i += 1  \n",
    "        return summary\n",
    "    \n",
    "class RidgeRegressionRiskGenerator(SimpleRegressionRiskGenerator):\n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Function to execute training either based on the data that you load from file or passed in as argument.\n",
    "        When X, Y are passed in as argument, would train the model based on the training dataset passed in, and over write\n",
    "        the existing data cached in the risk generator obj. If you implement some new machine learning model rather than using\n",
    "        existing machine learning model by some python package, please seperate the implementation of the model in another class,\n",
    "        and initialize an instance of that model in your setup function rather than implement the model directly in the fit function,\n",
    "        so that we could seprate the business logics with the machine learning model maintaining logics, and those model could be reused\n",
    "        somewhere else too.\"\"\"\n",
    "        self._model = {} # dict to store all the regression models (one for each asset/fund)\n",
    "        alpha = self._hyperparameters.get('alpha')\n",
    "        for i in range(self._Y_train.shape[1]):\n",
    "            ridge = Ridge(alpha = alpha, fit_intercept=False)\n",
    "            ridge.fit(self._X_train,self._Y_train[:,i])\n",
    "            self._model['fund'+str(i+1)] = ridge\n",
    "    \n",
    "    def model_summary(self):\n",
    "        \"\"\"Function that provide summary of model result: prediction accuracy, different matrix \n",
    "            to measure the model, and hyper-parameters of the model\"\n",
    "\n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                dict {str: float/dataframe}\n",
    "                key is the staticial measure name\n",
    "                value is the statical measure, either a number or a matrix or a dataframe\n",
    "        \"\"\"\n",
    "        summary = dict()\n",
    "        summary['hyperparameter'] = self._hyperparameters\n",
    "        summary['rmse score'] = {}\n",
    "        i = 0\n",
    "        for fund in self._model.keys():\n",
    "            mse = mean_squared_error(y_true = self._Y_test[:,i], y_pred = self._Y_pred[fund])\n",
    "            rmse = math.sqrt(mse)\n",
    "            summary['rmse score'][fund] = rmse\n",
    "            i += 1  \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test our risk generator classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>NAS:APGAX - Return</th>\n",
       "      <th>NAS:APGCX - Return</th>\n",
       "      <th>NAS:ANIAX - Return</th>\n",
       "      <th>NAS:ANMCX - Return</th>\n",
       "      <th>NAS:GSCIX - Return</th>\n",
       "      <th>NAS:GXXAX - Return</th>\n",
       "      <th>NAS:JBGIX - Return</th>\n",
       "      <th>NAS:RAGTX - Return</th>\n",
       "      <th>NAS:PGWAX - Return</th>\n",
       "      <th>NAS:ANCMX - Return</th>\n",
       "      <th>NAS:PQNAX - Return</th>\n",
       "      <th>NAS:PRXIX - Return</th>\n",
       "      <th>NAS:RMDAX - Return</th>\n",
       "      <th>NAS:JGVVX - Return</th>\n",
       "      <th>NAS:VGRIX - Return</th>\n",
       "      <th>NAS:JLGMX - Return</th>\n",
       "      <th>NAS:JLVMX - Return</th>\n",
       "      <th>NAS:OLGCX - Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sep-20</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-5.42</td>\n",
       "      <td>-3.76</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-4.12</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-4.18</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-4.36</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>-4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aug-20</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.07</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>5.08</td>\n",
       "      <td>7.10</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>8.74</td>\n",
       "      <td>12.96</td>\n",
       "      <td>7.51</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6.90</td>\n",
       "      <td>9.59</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.78</td>\n",
       "      <td>4.96</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jul-20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>6.07</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.12</td>\n",
       "      <td>5.76</td>\n",
       "      <td>6.13</td>\n",
       "      <td>1.90</td>\n",
       "      <td>9.64</td>\n",
       "      <td>7.80</td>\n",
       "      <td>8.12</td>\n",
       "      <td>6.30</td>\n",
       "      <td>3.91</td>\n",
       "      <td>7.91</td>\n",
       "      <td>9.43</td>\n",
       "      <td>3.84</td>\n",
       "      <td>9.87</td>\n",
       "      <td>2.95</td>\n",
       "      <td>9.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun-20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.71</td>\n",
       "      <td>6.61</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.37</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5.94</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May-20</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.36</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.41</td>\n",
       "      <td>10.28</td>\n",
       "      <td>7.93</td>\n",
       "      <td>1.23</td>\n",
       "      <td>12.06</td>\n",
       "      <td>7.45</td>\n",
       "      <td>8.56</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6.32</td>\n",
       "      <td>12.43</td>\n",
       "      <td>8.21</td>\n",
       "      <td>3.78</td>\n",
       "      <td>9.08</td>\n",
       "      <td>3.96</td>\n",
       "      <td>8.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  NAS:APGAX - Return  NAS:APGCX - Return  NAS:ANIAX - Return  \\\n",
       "0  Sep-20               -3.50               -3.56               -0.33   \n",
       "1  Aug-20                6.12                6.07               -0.20   \n",
       "2  Jul-20                6.14                6.07                1.26   \n",
       "3  Jun-20                2.00                1.94                1.47   \n",
       "4  May-20                8.44                8.36                2.48   \n",
       "\n",
       "   NAS:ANMCX - Return  NAS:GSCIX - Return  NAS:GXXAX - Return  \\\n",
       "0               -0.47               -5.42               -3.76   \n",
       "1               -0.19                5.08                7.10   \n",
       "2                1.12                5.76                6.13   \n",
       "3                1.48                1.76                0.63   \n",
       "4                2.41               10.28                7.93   \n",
       "\n",
       "   NAS:JBGIX - Return  NAS:RAGTX - Return  NAS:PGWAX - Return  \\\n",
       "0                0.18               -4.12               -3.50   \n",
       "1               -0.57                8.74               12.96   \n",
       "2                1.90                9.64                7.80   \n",
       "3                1.71                6.61                5.09   \n",
       "4                1.23               12.06                7.45   \n",
       "\n",
       "   NAS:ANCMX - Return  NAS:PQNAX - Return  NAS:PRXIX - Return  \\\n",
       "0               -0.78               -2.23               -2.80   \n",
       "1                7.51                1.65                1.64   \n",
       "2                8.12                6.30                3.91   \n",
       "3                4.49                0.16                3.79   \n",
       "4                8.56                4.86                6.32   \n",
       "\n",
       "   NAS:RMDAX - Return  NAS:JGVVX - Return  NAS:VGRIX - Return  \\\n",
       "0               -0.81               -4.18               -3.05   \n",
       "1                6.90                9.59                4.75   \n",
       "2                7.91                9.43                3.84   \n",
       "3                3.37                5.19                0.02   \n",
       "4               12.43                8.21                3.78   \n",
       "\n",
       "   NAS:JLGMX - Return  NAS:JLVMX - Return  NAS:OLGCX - Return  \n",
       "0               -4.36               -2.69               -4.41  \n",
       "1               10.78                4.96               10.67  \n",
       "2                9.87                2.95                9.79  \n",
       "3                5.94                2.10                5.86  \n",
       "4                9.08                3.96                8.95  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data samples\n",
    "import pandas as pd\n",
    "index = pd.read_csv('Index.csv')\n",
    "fund = pd.read_csv('Fund.csv')\n",
    "libor_data = pd.read_csv('USD_3M_LIBOR.csv')\n",
    "fund.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3436.19, 3363.0, 2580.77, 677.69, 3392.2],\n",
       "       [3505.42, 3500.31, 2577.19, 677.83, 3401.53],\n",
       "       [3455.6, 3271.12, 2605.74, 677.97, 3445.17],\n",
       "       ...,\n",
       "       [893.87, 1320.28, 1087.91, 526.72, 1092.73],\n",
       "       [888.02, 1314.95, 1067.54, 524.21, 1071.93],\n",
       "       [902.76, 1429.4, 1046.1, 521.57, 1058.22]], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Morningstar MSCI Emerging Markets - Close',\n",
       " 'S&P 500 PR- Close',\n",
       " 'BBgBarc US Treasury TR USD(1972) - Close',\n",
       " 'LIBOR 3 Mon Interbank Eurodollar Inv TR - Close',\n",
       " 'BBgBarc US Credit TR USD - Close']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of factors used for testing the code (corresponding to indexes in the dataset 'index')\n",
    "factors = list(index.columns[1:])\n",
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAS:RMDAX - Return</th>\n",
       "      <th>NAS:RAGTX - Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.81</td>\n",
       "      <td>-4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.90</td>\n",
       "      <td>8.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.91</td>\n",
       "      <td>9.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.37</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.43</td>\n",
       "      <td>12.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>13.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-13.14</td>\n",
       "      <td>-10.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.60</td>\n",
       "      <td>-4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.09</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.12</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.50</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.54</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.59</td>\n",
       "      <td>-6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.57</td>\n",
       "      <td>-3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.13</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.38</td>\n",
       "      <td>5.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-5.72</td>\n",
       "      <td>-8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.30</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.45</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.88</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.09</td>\n",
       "      <td>11.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-10.09</td>\n",
       "      <td>-6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.09</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-12.38</td>\n",
       "      <td>-12.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.06</td>\n",
       "      <td>11.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.06</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.47</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.34</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.12</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-1.66</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-4.21</td>\n",
       "      <td>-13.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>5.56</td>\n",
       "      <td>12.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8.43</td>\n",
       "      <td>16.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-5.68</td>\n",
       "      <td>-11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-2.22</td>\n",
       "      <td>-2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-9.55</td>\n",
       "      <td>-9.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>-10.36</td>\n",
       "      <td>-9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-2.20</td>\n",
       "      <td>-6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-5.81</td>\n",
       "      <td>-11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>6.64</td>\n",
       "      <td>10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-5.05</td>\n",
       "      <td>-15.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-4.81</td>\n",
       "      <td>-3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>8.34</td>\n",
       "      <td>16.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>8.58</td>\n",
       "      <td>15.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-14.02</td>\n",
       "      <td>-14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-6.92</td>\n",
       "      <td>-13.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-6.14</td>\n",
       "      <td>-9.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>-2.48</td>\n",
       "      <td>-3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-2.09</td>\n",
       "      <td>-5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>16.37</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-13.22</td>\n",
       "      <td>-14.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-15.57</td>\n",
       "      <td>-27.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2.37</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>9.97</td>\n",
       "      <td>-8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-24.25</td>\n",
       "      <td>-17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-10.09</td>\n",
       "      <td>-12.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NAS:RMDAX - Return  NAS:RAGTX - Return\n",
       "0                 -0.81               -4.12\n",
       "1                  6.90                8.74\n",
       "2                  7.91                9.64\n",
       "3                  3.37                6.61\n",
       "4                 12.43               12.06\n",
       "5                 14.20               13.31\n",
       "6                -13.14              -10.15\n",
       "7                 -4.60               -4.33\n",
       "8                  2.09                6.87\n",
       "9                  2.12                0.88\n",
       "10                 6.50                7.28\n",
       "11                -0.54                2.54\n",
       "12                -1.59               -6.01\n",
       "13                -1.57               -3.60\n",
       "14                 2.13                2.63\n",
       "15                 8.38                5.83\n",
       "16                -5.72               -8.04\n",
       "17                 5.30                6.59\n",
       "18                 1.45                2.44\n",
       "19                 4.88                5.47\n",
       "20                15.09               11.41\n",
       "21               -10.09               -6.68\n",
       "22                 1.09               -0.45\n",
       "23               -12.38              -12.63\n",
       "24                 0.00               -0.60\n",
       "25                 6.06               11.13\n",
       "26                 2.06                0.41\n",
       "27                 0.00               -0.43\n",
       "28                 3.47                6.98\n",
       "29                -2.34                0.27\n",
       "..                  ...                 ...\n",
       "210                1.12               -0.83\n",
       "211               -1.66               -0.44\n",
       "212               -0.55               -0.28\n",
       "213               -4.21              -13.53\n",
       "214                5.56               12.19\n",
       "215                8.43               16.14\n",
       "216               -5.68              -11.68\n",
       "217               -2.22               -2.46\n",
       "218               -9.55               -9.49\n",
       "219              -10.36               -9.07\n",
       "220               -2.20               -6.62\n",
       "221               -5.81              -11.50\n",
       "222                6.64               10.18\n",
       "223               -5.05              -15.07\n",
       "224               -4.81               -3.86\n",
       "225                2.00                4.59\n",
       "226                8.34               16.31\n",
       "227                8.58               15.16\n",
       "228              -14.02              -14.98\n",
       "229               -6.92              -13.30\n",
       "230               -6.14               -9.61\n",
       "231               -2.48               -3.49\n",
       "232               -2.09               -5.74\n",
       "233               16.37                8.20\n",
       "234              -13.22              -14.39\n",
       "235              -15.57              -27.44\n",
       "236                2.37                5.95\n",
       "237                9.97               -8.99\n",
       "238              -24.25              -17.93\n",
       "239              -10.09              -12.32\n",
       "\n",
       "[240 rows x 2 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test class SimpleRegressionRiskGenerator with data sample \n",
    "x = SimpleRegressionRiskGenerator(risk_generator_name = 'Regression', risk_factors = factors)\n",
    "x.set_up(risk_factors = factors, hyperparameters = {}, data_path = {'index': 'Index.csv', 'fund': 'Fund.csv','libor':'USD_3M_LIBOR.csv'})\n",
    "x.load_raw_data()\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()\n",
    "x.get_vol_factor_score()\n",
    "x.vol_score\n",
    "x.select_top_n_funds_with_factor_score(2,x.vol_score)\n",
    "x._assets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fund1': array([ 2.07878950e-03, -5.39625757e-05,  7.03559194e-03, -1.12721661e-02,\n",
       "        -4.44738151e-03]),\n",
       " 'fund2': array([ 2.08042673e-03, -3.31761405e-05,  7.12772084e-03, -1.14599806e-02,\n",
       "        -4.51909715e-03]),\n",
       " 'fund3': array([-0.00077314,  0.00016831,  0.00091984, -0.        , -0.        ]),\n",
       " 'fund4': array([-0.00076481,  0.0001626 ,  0.00091961, -0.00010555,  0.        ]),\n",
       " 'fund5': array([-0.00042997, -0.00110726, -0.00427445,  0.00365444,  0.00444184]),\n",
       " 'fund6': array([ 0.00133162, -0.00227396, -0.00632484,  0.00097823,  0.00586219]),\n",
       " 'fund7': array([-0.00099603,  0.000243  ,  0.00280407, -0.00138084, -0.00093212]),\n",
       " 'fund8': array([ 0.00272676, -0.00167255, -0.00315705, -0.00324775,  0.00266686]),\n",
       " 'fund9': array([ 2.79307360e-03, -9.79185966e-04,  2.76174672e-04, -7.12081344e-03,\n",
       "         6.14397768e-05]),\n",
       " 'fund10': array([ 0.00121518, -0.0006527 ,  0.0009397 , -0.00400219, -0.        ]),\n",
       " 'fund11': array([-0.00078249, -0.        , -0.00369934,  0.00497501,  0.00298047]),\n",
       " 'fund12': array([-0.00245035,  0.00011334,  0.00215515,  0.00174561,  0.00054157]),\n",
       " 'fund13': array([ 0.00203353, -0.00197962, -0.00301783, -0.00296147,  0.0032502 ]),\n",
       " 'fund14': array([ 0.00320324, -0.00272738, -0.00520264, -0.00293956,  0.00455248]),\n",
       " 'fund15': array([ 0.00083115, -0.00140829, -0.00413186,  0.00161506,  0.00364975]),\n",
       " 'fund16': array([ 2.53140236e-03, -5.36489646e-04, -1.33662724e-04, -5.61027043e-03,\n",
       "        -1.08159608e-05]),\n",
       " 'fund17': array([ 0.00028692, -0.00073849, -0.00198226,  0.        ,  0.00234541]),\n",
       " 'fund18': array([ 2.54935078e-03, -5.37703756e-04, -1.40843491e-04, -5.73264450e-03,\n",
       "        -2.36454483e-05])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test class LassoRegressionRiskGenerator with data sample \n",
    "x = LassoRegressionRiskGenerator(risk_generator_name = 'Lasso', risk_factors = factors)\n",
    "x.set_up(risk_factors = factors, hyperparameters = {'alpha': 0.6, 'max_iter': 100000}, data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'})\n",
    "x.load_raw_data()\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.betas_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fund1': array([ 2.11348957e-03,  8.77724063e-05,  8.02591079e-03, -1.22046655e-02,\n",
       "        -5.17314555e-03]),\n",
       " 'fund2': array([ 0.00211513,  0.00010856,  0.00811803, -0.01239247, -0.00524485]),\n",
       " 'fund3': array([-0.00077539,  0.00028588,  0.00166696, -0.00069129, -0.00052927]),\n",
       " 'fund4': array([-0.00076975,  0.00027735,  0.00167457, -0.00081874, -0.00052467]),\n",
       " 'fund5': array([-0.00046369, -0.00128081, -0.00538446,  0.0046839 ,  0.00526588]),\n",
       " 'fund6': array([ 0.00132122, -0.0024485 , -0.00742834,  0.00199497,  0.00666041]),\n",
       " 'fund7': array([-0.00098563,  0.00041751,  0.00390744, -0.00239748, -0.00173025]),\n",
       " 'fund8': array([ 0.00272908, -0.00175017, -0.00354027, -0.0029547 ,  0.00296803]),\n",
       " 'fund9': array([ 0.00280196, -0.00093568,  0.00069558, -0.00755631, -0.00021521]),\n",
       " 'fund10': array([ 0.00124279, -0.00053761,  0.00177562, -0.00480037, -0.00060412]),\n",
       " 'fund11': array([-0.00081631, -0.00017049, -0.0047979 ,  0.00599521,  0.0037951 ]),\n",
       " 'fund12': array([-2.47920811e-03,  7.19866443e-05,  1.83637425e-03,  2.06474668e-03,\n",
       "         7.85310437e-04]),\n",
       " 'fund13': array([ 0.00203586, -0.00205723, -0.003401  , -0.00266846,  0.00355134]),\n",
       " 'fund14': array([ 0.00320556, -0.002805  , -0.00558588, -0.0026465 ,  0.00485367]),\n",
       " 'fund15': array([ 0.00082075, -0.00158282, -0.00523535,  0.0026318 ,  0.00444796]),\n",
       " 'fund16': array([ 0.00255957, -0.00049256,  0.00020456, -0.00594702, -0.00026739]),\n",
       " 'fund17': array([ 0.00027862, -0.00089732, -0.00296907,  0.0008995 ,  0.00306308]),\n",
       " 'fund18': array([ 0.0025777 , -0.00046674,  0.00037113, -0.00622254, -0.00040591])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test class RidgeRegressionRiskGenerator with data sample \n",
    "x = RidgeRegressionRiskGenerator(risk_generator_name = 'Ridge', risk_factors = factors)\n",
    "x.set_up(risk_factors = factors, hyperparameters = {'alpha': 0.4}, data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'})\n",
    "x.load_raw_data()\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.betas_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to set up hyperparameters using a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a YAML file (config file) containing one set of hyperparameters \n",
    "\n",
    "params = {'alpha': 0.7, 'max_iter': 10000}\n",
    "\n",
    "with open('params.yaml', 'w') as f:\n",
    "    data = yaml.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fund1': array([ 2.11348903e-03,  8.77687226e-05,  8.02588560e-03, -1.22046415e-02,\n",
       "        -5.17312744e-03]),\n",
       " 'fund2': array([ 0.00211513,  0.00010855,  0.008118  , -0.01239244, -0.00524483]),\n",
       " 'fund3': array([-0.00077539,  0.00028588,  0.00166696, -0.00069129, -0.00052927]),\n",
       " 'fund4': array([-0.00076975,  0.00027735,  0.00167457, -0.00081873, -0.00052467]),\n",
       " 'fund5': array([-0.00046369, -0.00128081, -0.00538444,  0.00468389,  0.00526587]),\n",
       " 'fund6': array([ 0.00132122, -0.00244849, -0.00742832,  0.00199495,  0.0066604 ]),\n",
       " 'fund7': array([-0.00098563,  0.00041751,  0.00390743, -0.00239747, -0.00173025]),\n",
       " 'fund8': array([ 0.00272908, -0.00175017, -0.00354026, -0.00295471,  0.00296803]),\n",
       " 'fund9': array([ 0.00280195, -0.00093568,  0.00069557, -0.00755631, -0.00021521]),\n",
       " 'fund10': array([ 0.00124279, -0.00053761,  0.00177562, -0.00480037, -0.00060411]),\n",
       " 'fund11': array([-0.00081631, -0.00017049, -0.00479788,  0.0059952 ,  0.00379509]),\n",
       " 'fund12': array([-2.47920798e-03,  7.19867177e-05,  1.83637492e-03,  2.06474587e-03,\n",
       "         7.85309899e-04]),\n",
       " 'fund13': array([ 0.00203586, -0.00205723, -0.00340099, -0.00266847,  0.00355134]),\n",
       " 'fund14': array([ 0.00320556, -0.002805  , -0.00558587, -0.0026465 ,  0.00485366]),\n",
       " 'fund15': array([ 0.00082075, -0.00158282, -0.00523534,  0.00263179,  0.00444795]),\n",
       " 'fund16': array([ 0.00255957, -0.00049256,  0.00020455, -0.00594702, -0.00026738]),\n",
       " 'fund17': array([ 0.00027862, -0.00089732, -0.00296907,  0.0008995 ,  0.00306308]),\n",
       " 'fund18': array([ 0.0025777 , -0.00046674,  0.00037113, -0.00622254, -0.0004059 ])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = RidgeRegressionRiskGenerator(risk_generator_name = 'Ridge', risk_factors = factors)\n",
    "x.set_up(risk_factors = factors, hyperparameters = {'alpha': 0.4}, \n",
    "         data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'})\n",
    "x.load_raw_data()\n",
    "x.set_hyper_parameter(config_path = 'params.yaml')\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': '0.7', 'max_iter': '10000'}\n"
     ]
    }
   ],
   "source": [
    "x.print_hyper_parameter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L53jWNoJaThL"
   },
   "outputs": [],
   "source": [
    "class RiskScenarioBased:\n",
    "    \"\"\"Mixin Class to provide risk scenario that we would apply on the factors model to see how a portfolio would react to risk\"\"\"\n",
    "    \n",
    "    def __init__(self, scenario_name, risk_factors):\n",
    "        self._scenario_name = scenario_name\n",
    "        self._risk_factors = risk_factors\n",
    "    \n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement set_up function!\")\n",
    "    \n",
    "    def risk_factors(self):\n",
    "        \"\"\"Print the list of risk factors that you use in this scenario, do not hard coded the return list, the information\n",
    "        should be able to be gathered from private variables either from init function\"\"\"\n",
    "        return self._risk_factors\n",
    "    \n",
    "    def generate_scenario(self, **kwargs):\n",
    "        \"\"\"Function to generate scenario based on config you provide in **kwargs, you may have some machine learning based model\n",
    "        to derive the correlation of risk factors, and generate correlated risk scenarios, or you could assume that the movement\n",
    "        of risk factor are independent of each other, and apply different shock on the risk factors\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement set_up function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_Mog_s9yaThR"
   },
   "outputs": [],
   "source": [
    "# Define a naive risk scenario where the user inputs the percentage shock directly in setup function, and then outputs\n",
    "# the shocked factors data\n",
    "\n",
    "class NaiveRiskScenario(RiskScenarioBased):\n",
    "    \"\"\"Risk Scenarios that the user passed in shock on each risk factors, and assume that the factors are independent\n",
    "    of each other\n",
    "    \"\"\"\n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator\"\"\"\n",
    "        self._data_path = kwargs.get('data_path') # dict: {'fund': data_path for fund data, 'index': data_path for index data}\n",
    "        self._shocks = kwargs.get('shocks') # dict: {'factor1': shock1, ...} where shock1 = -0.1 to create a -10% shock\n",
    "    \n",
    "    def print_shocks(self, **kwargs):\n",
    "        \"\"\"Print the percentage shocks applied on each risk factor\"\"\"\n",
    "        print(self._shocks)\n",
    "    \n",
    "    def load_raw_data(self, **kwargs):\n",
    "        \"\"\"Function to load raw data from source, should be able to support \n",
    "        reading data from flat file or sql database. Please just implement the one using flat file now,\n",
    "        later we would provide the sql python package that we would want to utilize for the database task\n",
    "        You may also want to have some data cleaning on the raw data, please define private method for data transformation.\n",
    "        and the data should be saved as private variable, as it would be used for later training and testing process.\n",
    "        \n",
    "        Parameters:\n",
    "            source_type: str\n",
    "                flat file type or sql, if it is flat file, file directory or \n",
    "                path need to be passed in as argument or in the setup function\n",
    "                If it is sql, connection need to be extablished in setup function\n",
    "                please avoid any hard coded name in the class, and set global variable to define those file name\n",
    "        \"\"\"\n",
    "        self._factors_data = pd.read_csv(self._data_path.get('index'))\n",
    "    \n",
    "    def generate_scenario(self, **kwargs):\n",
    "        \"\"\"Function to generate scenario based on config you provide in **kwargs, you may have some machine learning based model\n",
    "        to derive the correlation of risk factors, and generate correlated risk scenarios, or you could assume that the movement\n",
    "        of risk factor are independent of each other, and apply different shock on the risk factors\"\"\"\n",
    "        X = self._factors_data\n",
    "        X_shocked = X.copy()\n",
    "        for factor in self._risk_factors:\n",
    "            shock = self._shocks.get(factor)\n",
    "            if shock is None:\n",
    "                shock = 0.0\n",
    "            X_shocked[factor] = X[factor]*(1+shock)\n",
    "        self._factors_data_shocked = X_shocked\n",
    "        return self._factors_data_shocked\n",
    "    \n",
    "# Later we would define Event Based Risk Scenario and Machine Learning Base Risk Scenarios\n",
    "class PCARiskScenario(NaiveRiskScenario):\n",
    "    \"\"\"A simple Machine Learning Risk Scenario that you want to try is a PCA based Risk Scenarios. You could do a PCA on the list of risk factors,\n",
    "    and use the PCA to represent movement of the factors, and you may have two derivation of this scenarios generation, the user should be able to either\n",
    "    provide you shock they want on the principal component, or on the risk factor itself, and then you map it to the change on the pca component based on\n",
    "    some assume, and generate the output shock on the risk factors\"\"\"\n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator\"\"\"\n",
    "        self._data_path = kwargs.get('data_path') # dict: {'fund': data_path for fund data, 'index': data_path for index data}\n",
    "        self._shocks = kwargs.get('shocks') # dict: {'factor1': shock1, ...} where shock1 = -0.1 to create a -10% shock\n",
    "        self._factor_choice = kwargs.get('factor_choice') # 'pc' to shock the principal components, 'factor' to shock specific risk factors \n",
    "        \n",
    "    def generate_scenario(self, **kwargs):\n",
    "        \"\"\"Function to generate scenario based on config you provide in **kwargs, you may have some machine learning based model\n",
    "        to derive the correlation of risk factors, and generate correlated risk scenarios, or you could assume that the movement\n",
    "        of risk factor are independent of each other, and apply different shock on the risk factors\"\"\"\n",
    "        if self._factor_choice == 'pc': # this means we shock the principal components\n",
    "            X = self._factors_data.to_numpy()[:,1:]# convert to numpy array and get rid of dates\n",
    "            pca = PCA(whiten = True).fit(X)\n",
    "            threshold = 0.85 # set a threshold to decide the number of principal components that should be kept\n",
    "            n_components = np.where(np.cumsum(pca.explained_variance_ratio_) >= threshold)[0][0] + 1\n",
    "            pca = PCA(n_components = n_components, whiten = True)\n",
    "            pc_X = pca.fit_transform(X)\n",
    "            pc_list = ['pc_'+str(i+1) for i in range(n_components)]\n",
    "            pc_shocked = pc_X.copy()\n",
    "            for i, pc in enumerate(pc_list):\n",
    "                shock = self._shocks.get(pc)\n",
    "                if shock is None:\n",
    "                    shock = 0.0\n",
    "                pc_shocked[:,i] = pc_shocked[:,i]*(1+shock)\n",
    "            X_shocked = pca.inverse_transform(pc_shocked)\n",
    "            self._factors_data_shocked = self._factors_data.copy()\n",
    "            self._factors_data_shocked.iloc[:,1:] = X_shocked\n",
    "            return self._factors_data_shocked   \n",
    "        elif self._factor_choice == 'factor': # this means we shock specific risk factors, just like naive risk secenario\n",
    "            return super().generate_scenario()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test our risk scenario classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shock0 = {'S&P 500 PR- Close': -0.2}\n",
    "nrs = NaiveRiskScenario(scenario_name = 'Naive', risk_factors = factors)\n",
    "nrs.set_up(data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'}, shocks = shock0)\n",
    "nrs.load_raw_data()\n",
    "nrs_x = nrs.generate_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Morningstar MSCI Emerging Markets - Close</th>\n",
       "      <th>S&amp;P 500 PR- Close</th>\n",
       "      <th>BBgBarc US Treasury TR USD(1972) - Close</th>\n",
       "      <th>LIBOR 3 Mon Interbank Eurodollar Inv TR - Close</th>\n",
       "      <th>BBgBarc US Credit TR USD - Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sep-20</td>\n",
       "      <td>3436.19</td>\n",
       "      <td>2690.400</td>\n",
       "      <td>2580.77</td>\n",
       "      <td>677.69</td>\n",
       "      <td>3392.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aug-20</td>\n",
       "      <td>3505.42</td>\n",
       "      <td>2800.248</td>\n",
       "      <td>2577.19</td>\n",
       "      <td>677.83</td>\n",
       "      <td>3401.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jul-20</td>\n",
       "      <td>3455.60</td>\n",
       "      <td>2616.896</td>\n",
       "      <td>2605.74</td>\n",
       "      <td>677.97</td>\n",
       "      <td>3445.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun-20</td>\n",
       "      <td>3292.46</td>\n",
       "      <td>2480.232</td>\n",
       "      <td>2576.30</td>\n",
       "      <td>678.09</td>\n",
       "      <td>3342.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May-20</td>\n",
       "      <td>3137.93</td>\n",
       "      <td>2435.448</td>\n",
       "      <td>2573.89</td>\n",
       "      <td>678.18</td>\n",
       "      <td>3282.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  Morningstar MSCI Emerging Markets - Close  S&P 500 PR- Close  \\\n",
       "0  Sep-20                                    3436.19           2690.400   \n",
       "1  Aug-20                                    3505.42           2800.248   \n",
       "2  Jul-20                                    3455.60           2616.896   \n",
       "3  Jun-20                                    3292.46           2480.232   \n",
       "4  May-20                                    3137.93           2435.448   \n",
       "\n",
       "   BBgBarc US Treasury TR USD(1972) - Close  \\\n",
       "0                                   2580.77   \n",
       "1                                   2577.19   \n",
       "2                                   2605.74   \n",
       "3                                   2576.30   \n",
       "4                                   2573.89   \n",
       "\n",
       "   LIBOR 3 Mon Interbank Eurodollar Inv TR - Close  \\\n",
       "0                                           677.69   \n",
       "1                                           677.83   \n",
       "2                                           677.97   \n",
       "3                                           678.09   \n",
       "4                                           678.18   \n",
       "\n",
       "   BBgBarc US Credit TR USD - Close  \n",
       "0                           3392.20  \n",
       "1                           3401.53  \n",
       "2                           3445.17  \n",
       "3                           3342.11  \n",
       "4                           3282.14  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrs_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "shock1 = {'pc_1': -0.2}\n",
    "pcars = PCARiskScenario(scenario_name = 'PCA', risk_factors = factors)\n",
    "pcars.set_up(data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'}, shocks = shock1, factor_choice = 'pc')\n",
    "pcars.load_raw_data()\n",
    "pcars_x = pcars.generate_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Morningstar MSCI Emerging Markets - Close</th>\n",
       "      <th>S&amp;P 500 PR- Close</th>\n",
       "      <th>BBgBarc US Treasury TR USD(1972) - Close</th>\n",
       "      <th>LIBOR 3 Mon Interbank Eurodollar Inv TR - Close</th>\n",
       "      <th>BBgBarc US Credit TR USD - Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sep-20</td>\n",
       "      <td>3400.098415</td>\n",
       "      <td>2716.372291</td>\n",
       "      <td>2469.697276</td>\n",
       "      <td>688.100804</td>\n",
       "      <td>3164.158054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aug-20</td>\n",
       "      <td>3454.215496</td>\n",
       "      <td>2764.787878</td>\n",
       "      <td>2500.104793</td>\n",
       "      <td>691.094858</td>\n",
       "      <td>3213.017018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jul-20</td>\n",
       "      <td>3399.847333</td>\n",
       "      <td>2716.147661</td>\n",
       "      <td>2469.556197</td>\n",
       "      <td>688.086913</td>\n",
       "      <td>3163.931367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jun-20</td>\n",
       "      <td>3283.824653</td>\n",
       "      <td>2612.348526</td>\n",
       "      <td>2404.364920</td>\n",
       "      <td>681.667900</td>\n",
       "      <td>3059.181665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May-20</td>\n",
       "      <td>3212.909949</td>\n",
       "      <td>2548.905026</td>\n",
       "      <td>2364.519089</td>\n",
       "      <td>677.744508</td>\n",
       "      <td>2995.157165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  Morningstar MSCI Emerging Markets - Close  S&P 500 PR- Close  \\\n",
       "0  Sep-20                                3400.098415        2716.372291   \n",
       "1  Aug-20                                3454.215496        2764.787878   \n",
       "2  Jul-20                                3399.847333        2716.147661   \n",
       "3  Jun-20                                3283.824653        2612.348526   \n",
       "4  May-20                                3212.909949        2548.905026   \n",
       "\n",
       "   BBgBarc US Treasury TR USD(1972) - Close  \\\n",
       "0                               2469.697276   \n",
       "1                               2500.104793   \n",
       "2                               2469.556197   \n",
       "3                               2404.364920   \n",
       "4                               2364.519089   \n",
       "\n",
       "   LIBOR 3 Mon Interbank Eurodollar Inv TR - Close  \\\n",
       "0                                       688.100804   \n",
       "1                                       691.094858   \n",
       "2                                       688.086913   \n",
       "3                                       681.667900   \n",
       "4                                       677.744508   \n",
       "\n",
       "   BBgBarc US Credit TR USD - Close  \n",
       "0                       3164.158054  \n",
       "1                       3213.017018  \n",
       "2                       3163.931367  \n",
       "3                       3059.181665  \n",
       "4                       2995.157165  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcars_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcars.set_up(data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'}, shocks = shock0, factor_choice = 'factor')\n",
    "pcars.load_raw_data()\n",
    "pcars_x = pcars.generate_scenario()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IW7rvf-4aThX"
   },
   "outputs": [],
   "source": [
    "class RiskSimulatorBased:\n",
    "    \"\"\"Simulator class that load the risk factor information and risk scenario information, and output the performance of the portfolio\n",
    "    after we apply specific kind of risk shock on the portfolio based on the risk analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, risk_generator_name, scenario_name):\n",
    "        \"\"\"initialize the risk generator and scenario based on the generator_name and scenario_name\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement set_up function!\")\n",
    "    \n",
    "    def run_simulation(self):\n",
    "        \"\"\"run simulation based on the portfolio that you set in risk_generator, and scenario\"\"\"\n",
    "    \n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator, you may want to setup parameters for risk generator and scenario here too.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement set_up function!\")\n",
    "    \n",
    "    def reset_portfolio(self, portfolio):\n",
    "        \"\"\"reset portfolio on the risk generator, and re-train to get beta for risk factors\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement reset_portfolio function!\")\n",
    "\n",
    "    def reset_scenario(self, scenario):\n",
    "        \"\"\"reset scenario on the scenario generator\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement reset_scenario function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskSimulatorFactory:\n",
    "    def get_generator(self, generator_name, risk_factors):\n",
    "        if generator_name == 'Regression':\n",
    "            return SimpleRegressionRiskGenerator(generator_name, risk_factors)\n",
    "        elif generator_name == 'Lasso':\n",
    "            return LassoRegressionRiskGenerator(generator_name, risk_factors)\n",
    "        elif generator_name == 'Ridge':\n",
    "            return RidgeRegressionRiskGenerator(generator_name, risk_factors)\n",
    "    def get_scenario(self, scenario_name, risk_factors):\n",
    "        if scenario_name == 'Naive':\n",
    "            return NaiveRiskScenario(scenario_name, risk_factors)\n",
    "        elif scenario_name == 'PCA':\n",
    "            return PCARiskScenario(scenario_name, risk_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uI0e2oHgaThd"
   },
   "outputs": [],
   "source": [
    "# define a risk simulator based on the naive risk scenario and pac risk scenario above, and also the regression risk factor generator,\n",
    "# and apply some shock on a portfolio of mutual fund to see how the price would move.\n",
    "\n",
    "class SimpleRiskSimulator(RiskSimulatorBased):\n",
    "    def __init__(self, risk_generator_name, scenario_name):\n",
    "        \"\"\"initialize the risk generator and scenario based on the generator_name and scenario_name\"\"\"\n",
    "        self._risk_generator_name = risk_generator_name\n",
    "        self._scenario_name = scenario_name\n",
    "    \n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator, you may want to setup parameters for risk generator and scenario here too.\"\"\"\n",
    "        self._risk_factors = kwargs.get('risk_factors') #list of risk factors\n",
    "        self._hyperparameters = kwargs.get('hyperparameters') # dict: {'hyperparameter1': value1, ...}\n",
    "        self._data_path = kwargs.get('data_path') # dict: {'fund': data_path for fund data, 'index': data_path for index data}\n",
    "        \n",
    "        self._factor_choice = kwargs.get('factor_choice')\n",
    "        self._shocks = kwargs.get('shocks')\n",
    "        \n",
    "        self._risk_generator = RiskSimulatorFactory().get_generator(self._risk_generator_name, self._risk_factors)\n",
    "        self._risk_scenario = RiskSimulatorFactory().get_scenario(self._scenario_name, self._risk_factors)\n",
    "    \n",
    "    def run_simulation(self):\n",
    "        \"\"\"run simulation based on the portfolio that you set in risk_generator, and scenario\"\"\"\n",
    "        self._risk_generator.set_up(risk_factors = self._risk_factors, hyperparameters = self._hyperparameters,\n",
    "                                    data_path = self._data_path)\n",
    "        self._risk_generator.load_raw_data()\n",
    "        self._risk_generator.split_train_test_data()\n",
    "        self._risk_generator.fit()\n",
    "        self._risk_generator.betas_fund()\n",
    "        self._beta = self._risk_generator.betas_output()[:,1:]  # get rid of the factor name\n",
    "        self._beta = self._beta.astype(np.float)\n",
    "        \n",
    "        self._risk_scenario.set_up(data_path = self._data_path, shocks = self._shocks, factor_choice = self._factor_choice)\n",
    "        self._risk_scenario.load_raw_data()\n",
    "        self._shocked_x = self._risk_scenario.generate_scenario().to_numpy()[:,1:] # get rid of the date\n",
    "        self._shocked_x = self._shocked_x.astype(np.float)\n",
    "\n",
    "        shocked_y = np.dot(self._shocked_x, self._beta)\n",
    "        return shocked_y\n",
    "    \n",
    "    def reset_portfolio(self, portfolio):\n",
    "        \"\"\"reset portfolio on the risk generator, and re-train to get beta for risk factors\"\"\"\n",
    "        new_data_path = {}\n",
    "        new_data_path['index'] = self._data_path.get('index')\n",
    "        new_data_path['fund'] = portfolio # portfolio is a string recording the data_path of new portfolio\n",
    "        self._risk_generator.set_up(risk_factors = self._risk_factors, hyperparameters = self._hyperparameters, \n",
    "                                    data_path = new_data_path)\n",
    "        self._risk_generator.load_raw_data()\n",
    "        self._risk_generator.split_train_test_data()\n",
    "        self._risk_generator.fit()\n",
    "        self._risk_generator.betas_fund()\n",
    "        new_beta = self._risk_generator.betas_output()[:,1:]\n",
    "        new_beta = new_beta.astype(np.float)\n",
    "        \n",
    "        new_shocked_y = np.dot(self._shocked_x, new_beta)\n",
    "        return new_shocked_y\n",
    "    \n",
    "    def reset_generator(self, generator):\n",
    "        \"\"\"reset risk generator and re-train to get beta for risk factors\"\"\"\n",
    "        new_generator_name = generator.get('risk_generator_name')\n",
    "        new_hyperparameters = generator.get('hyperparameters')\n",
    "        \n",
    "        new_risk_generator = RiskSimulatorFactory().get_generator(new_generator_name, self._risk_factors)\n",
    "        new_risk_generator.set_up(risk_factors = self._risk_factors, hyperparameters = new_hyperparameters,\n",
    "                                    data_path = self._data_path)\n",
    "        new_risk_generator.load_raw_data()\n",
    "        new_risk_generator.split_train_test_data()\n",
    "        new_risk_generator.fit()\n",
    "        new_risk_generator.betas_fund()\n",
    "        new_beta = new_risk_generator.betas_output()[:,1:]  # get rid of the factor name\n",
    "        new_beta = new_beta.astype(np.float)\n",
    "        \n",
    "        new_shocked_y = np.dot(self._shocked_x, new_beta)\n",
    "        return new_shocked_y\n",
    "        \n",
    "\n",
    "    def reset_scenario(self, scenario):\n",
    "        \"\"\"reset scenario on the scenario generator\"\"\"\n",
    "        new_scenario_name = scenario.get('scenario_name')\n",
    "        new_factor_choice = scenario.get('factor_choice')\n",
    "        new_shocks = scenario.get('shocks')\n",
    "        \n",
    "        new_risk_scenario = RiskSimulatorFactory().get_scenario(new_scenario_name, self._risk_factors)\n",
    "        new_risk_scenario.set_up(data_path = self._data_path, shocks = new_shocks, factor_choice = new_factor_choice)\n",
    "        new_risk_scenario.load_raw_data()\n",
    "        new_shocked_x = new_risk_scenario.generate_scenario().to_numpy()[:,1:]\n",
    "        new_shocked_x = new_shocked_x.astype(np.float)\n",
    "        \n",
    "        new_shocked_y = np.dot(new_shocked_x, self._beta)\n",
    "        return new_shocked_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator1 = SimpleRiskSimulator(risk_generator_name = 'Regression', scenario_name = 'Naive')\n",
    "simulator1.set_up(risk_factors = factors, data_path = {'index': 'Index.csv', 'fund': 'Fund.csv'}, shocks = shock0)\n",
    "shocked_y = simulator1.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.3921992 ,  2.32095925,  0.14291434, ...,  3.06064894,\n",
       "         1.88090455,  2.9656781 ],\n",
       "       [ 2.46945109,  2.39958251,  0.10963504, ...,  3.17968231,\n",
       "         1.84095787,  3.08687481],\n",
       "       [ 2.34973778,  2.27545113,  0.12024543, ...,  3.13581389,\n",
       "         2.04063527,  3.03604223],\n",
       "       ...,\n",
       "       [-1.36793268, -1.42157756,  0.47989198, ..., -1.43438257,\n",
       "        -0.10790335, -1.50618097],\n",
       "       [-1.40592365, -1.45958026,  0.46199701, ..., -1.43093398,\n",
       "        -0.11119687, -1.5027689 ],\n",
       "       [-1.4356656 , -1.48789114,  0.45008473, ..., -1.42332392,\n",
       "        -0.16996165, -1.49347286]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shocked_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_changed_shocked_y = simulator1.reset_scenario(scenario = {'scenario_name':'PCA', 'factor_choice':'pc', 'shocks':shock1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_changed_shocked_y = simulator1.reset_portfolio(portfolio = 'Fund2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Based Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do this assignment, you need to setup a mysql database on your local machine, and also import the sauma.core package provided by ca\n",
    "\n",
    "# please define the setup_connection in this class\n",
    "\n",
    "class SQLHandlerMixin:\n",
    "    \"\"\"Mixin class that you would include in the inheritance hierarchy to migrate all possible operation to SQL\n",
    "    so as to speed up calculation, you would need to integrate the sauma.core package and utilize the connection obj here\"\"\"\n",
    "    \n",
    "    def setup_connection(self, username, password):\n",
    "        \"\"\"initilize the connection obj here, and use it for any operation\"\"\"\n",
    "        self._conn = sauma.core.Connection(username=username, password=password)\n",
    "    \n",
    "    def setup_table_templates(self):\n",
    "        \"\"\"define the table template as local variable in this method for all derived class, \n",
    "        and utilize this method to setup tables\"\"\"\n",
    "        raise NotImplementedError(\"Derived Class need to implement this method\")\n",
    "    \n",
    "    def check_table_exist_or_not(self, schemas, table_name):\n",
    "        \"\"\"Please define this method to check whether a table under certain schemas exist or not\"\"\"\n",
    "        pass\n",
    "\n",
    "    def look_up_or_create_table(self, template, custom_table_name=None, custom_schemas_name=None):\n",
    "        \"\"\"Please define this method to create a table based on the template if a table does not exist, do nothing if table \n",
    "        already exist, you may want to use self.check_table_exist_or_not here, if custom_table_name is none, \n",
    "        you should be able to find it in template\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def drop_table(self, schemas, table_name):\n",
    "        pass\n",
    "    \n",
    "    def chunks_update_table(self, schema, table_name, dataframe, **kwargs):\n",
    "        \"\"\"when you have a large dataframe, it mays takes a long time to update the sql table if you upload it at once, you could actually\n",
    "        divide the table into smaller chunks and upload them piece by piece to speed up the process, as it is more memory efficient and use less cpu,\n",
    "        try to implement this method here too\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk factor generator (with SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the risk generator by including the sql mixin class into the inheritance hierarchy, and redefine all the data \n",
    "#collection and publishing process using SQL instead of csv file\n",
    "\n",
    "class SimpleRegressionRiskGeneratorSQL(SimpleRegressionRiskGenerator, SQLHandlerMixin):\n",
    "    \"\"\"Inlcude SQL Operation in Mutual Fund Performance Feature Calculation\"\"\"\n",
    "    def setup_table_templates(self):\n",
    "        \"\"\"Define all the table template as local variable here, all these table template should be defined as a global variable\n",
    "        in a python file, and import here for this class to use, please check the sauma.core documentation, the template \n",
    "        format should be something like:\n",
    "        {\n",
    "            \"tableName\": \"Test\",\n",
    "            \"schema\": \"test_db\",\n",
    "            \"primaryKey\":[\"id\"],\n",
    "            \"columns\": [{\"name\": \"id\",       \"type\":\"INTEGER\"},                           // case insensitive\n",
    "                        {\"name\": \"text_col\", \"type\":\"STRING\", \"size\":50},\n",
    "                        {\"name\": \"int_col\",  \"type\":\"INT\"}\n",
    "            ],\n",
    "            \"primaryKey\":[\"id\"],\n",
    "            \"description\": 'sample table to know about the format'\n",
    "        }\n",
    "        \n",
    "        \n",
    "        for example, you define a list of template under performance_feature/custom.py\n",
    "        so you could do from performance_feature.custom import TEMPLATE_A, TEMPLATE_B, TEMPLATE_C\n",
    "        and do self.templateA = TEMPLATE_A inside this class\n",
    "        and do self.look_up_or_create_table(self.templateA) to setup the table in the setup_table function\n",
    "        as the sauma.core package require a json obj as input, you may need to transoform the dictionary into a json obj by doing \n",
    "        import json\n",
    "        # Data to be written   \n",
    "            dictionary ={   \n",
    "              \"id\": \"04\",   \n",
    "              \"name\": \"sunil\",   \n",
    "              \"depatment\": \"HR\"\n",
    "            }   \n",
    "\n",
    "            # Serializing json    \n",
    "            json_object = json.dumps(dictionary)\n",
    "        \"\"\"\n",
    "        # take data from wrds for funds instead of morningstar\n",
    "        from table_templates import template_factor, template_funds, template_results\n",
    "        json_factor = json.dumps(template_factor)\n",
    "        json_funds = json.dumps(template_funds)\n",
    "        json_results = json.dumps(template_results)\n",
    "        self._templates = {'factor': json_factor, 'funds': json_funds, 'results': json_results}\n",
    "    \n",
    "    def check_table_exist_or_not(self, schema, table_name):\n",
    "        \"\"\"Please define this method to check whether a table under certain schema exist or not\"\"\"\n",
    "        c = self._conn.connect()\n",
    "        try:\n",
    "            self._conn.get_table(schema = schema, table_name = table_name) \n",
    "        except:\n",
    "            print(table_name + ' does not exist in schema ' + schema)\n",
    "        else: \n",
    "            print(table_name + ' exists in schema ' + schema)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def look_up_or_create_table(self, template, custom_table_name=None, custom_schema_name=None):\n",
    "        \"\"\"Please define this method to create a table based on the template if a table does not exist, do nothing if table \n",
    "        already exist, you may want to use self.check_table_exist_or_not here, if custom_table_name is none, \n",
    "        you should be able to find it in template\"\"\"\n",
    "        c = self._conn.connect()\n",
    "        if custom_table_name == None:\n",
    "            table_name = template.get('table_name')\n",
    "        else: \n",
    "            table_name = custom_table_name    \n",
    "        if custom_schema_name == None:\n",
    "            schema_name = template.get('schema')\n",
    "        else: \n",
    "            schema_name = custom_schema_name    \n",
    "        if not self.check_table_exist_or_not(schema = schema_name , table_name = table_name):\n",
    "                    template_custom = template\n",
    "                    template_custom['table_name'] = table_name\n",
    "                    template_custom['schema'] = schema_name\n",
    "                    template_custom = json.dumps(template_custom) # sauma.core package require a json obj as input\n",
    "                    self._conn.create_table(template_custom)  \n",
    "                    \n",
    "    def setup_tables(self):\n",
    "        \"\"\"setup all table based on the setup_table_templates\"\"\"\n",
    "        # first let us setup the tables for each risk factor\n",
    "        c = self._conn.connect()\n",
    "        sql = \"CREATE DATABASE IF NOT EXISTS factors\"\n",
    "        c.execute(sql)\n",
    "        template_factor = json.loads(self._templates.get('factor')) # json object back to a dict\n",
    "        for factor in self._risk_factors:\n",
    "            self.look_up_or_create_table(template = template_factor, custom_table_name = factor, custom_schema_name= None) \n",
    "        # then we create the table for the funds\n",
    "        sql = \"CREATE DATABASE IF NOT EXISTS funds\"\n",
    "        c.execute(sql)\n",
    "        template_funds = json.loads(self._templates.get('funds'))\n",
    "        self.look_up_or_create_table(template_funds, custom_table_name = 'funds', custom_schema_name = None) \n",
    "        # finally, we create the table for the results\n",
    "        sql = \"CREATE DATABASE IF NOT EXISTS results\"\n",
    "        c.execute(sql)\n",
    "        template_results = json.loads(self._templates.get('results'))\n",
    "        self.look_up_or_create_table(template_results, custom_table_name = 'results', custom_schema_name = None)\n",
    "        \n",
    "    def __init__(self, risk_generator_name, risk_factors, username, password):\n",
    "        SimpleRegressionRiskGenerator.__init__(self, risk_generator_name, risk_factors )\n",
    "        self.setup_connection(username, password)\n",
    "        self.setup_table_templates()\n",
    "        self.setup_tables()\n",
    "    \n",
    "    def update_raw_data(self):\n",
    "        \"\"\"assuming that your data source is the csv file containing all the raw data, load the raw data from csv, and update\n",
    "        the table which you already setup based on your template\"\"\"\n",
    "        c = self._conn.connect()\n",
    "        indiv_factors_data = {}\n",
    "        for factor, path in self._data_path.get('index').items(): # its a dict {factor name: path of csv file corresponding} factor name more covenient than index name\n",
    "            factor_data = pd.read_csv(path,sep=',', thousands=',')\n",
    "            factor_data.rename(columns={'Unnamed: 0': 'Date', \n",
    "                                        factor_data.columns[1]: factor_data.columns[1].split(' -')[0]}, inplace=True) \n",
    "            # transfo of data imported directly from Morningstar \n",
    "            self._conn.update_table(table_name = factor , dataframe = factor_data, schema = 'factors', index = False, if_exists = 'replace')\n",
    "            indiv_factors_data[factor] = self._conn.get_dataframe(table_name = factor, schema = 'factors') # indiv_factors_data is a dict\n",
    "        # merge all dataframes of individual factors on date column \n",
    "        red = partial(pd.merge, on='Date', how='outer')\n",
    "        self._factors_data = reduce(red, indiv_factors_data.values())\n",
    "        # now let us get the funds data\n",
    "        funds_data = pd.read_csv(self._data_path.get('fund'),sep=',', thousands=',')\n",
    "        self._conn.update_table(table_name = 'funds' , dataframe = funds_data, schema = 'Funds', index = False, if_exists = 'replace')\n",
    "        self._assets_data = self._conn.get_dataframe(table_name = 'funds', schema = 'Funds')\n",
    "        \n",
    "    def load_SQL_data(self):\n",
    "        c = self._conn.connect()\n",
    "        indiv_factors_data = {}\n",
    "        for factor, path in self._data_path.get('index').items(): # its a dict {factor name: path of csv file corresponding} factor name more covenient than index name\n",
    "            indiv_factors_data[factor] = self._conn.get_dataframe(table_name = factor, schema = 'factors') # indiv_factors_data is a dict\n",
    "        # merge all dataframes of individual factors on date column \n",
    "        red = partial(pd.merge, on='Date', how='outer')\n",
    "        self._factors_data = reduce(red, indiv_factors_data.values())\n",
    "        # now let us get the funds data\n",
    "        self._assets_data = self._conn.get_dataframe(table_name = 'funds', schema = 'Funds')\n",
    "        \n",
    "    def publish_result(self):\n",
    "        \"\"\"upload the result data you have to sql, you would need to setup a json template to show how the result table would looks like too\"\"\"\n",
    "        df = pd.DataFrame.from_dict(self._betas_fund)\n",
    "        df.insert(0, 'Factor', self._risk_factors)\n",
    "        self._conn.update_table(table_name = 'results' , dataframe = df, schema = 'Results', index = False, if_exists = 'replace')\n",
    "        return()\n",
    "\n",
    "class LassoRegressionRiskGeneratorSQL(SimpleRegressionRiskGeneratorSQL):\n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Function to execute training either based on the data that you load from file or passed in as argument.\n",
    "        When X, Y are passed in as argument, would train the model based on the training dataset passed in, and over write\n",
    "        the existing data cached in the risk generator obj. If you implement some new machine learning model rather than using\n",
    "        existing machine learning model by some python package, please seperate the implementation of the model in another class,\n",
    "        and initialize an instance of that model in your setup function rather than implement the model directly in the fit function,\n",
    "        so that we could seprate the business logics with the machine learning model maintaining logics, and those model could be reused\n",
    "        somewhere else too.\"\"\"\n",
    "        self._model = {} # dict to store all the regression models (one for each asset/fund)\n",
    "        alpha = self._hyperparameters.get('alpha')\n",
    "        max_iter = self._hyperparameters.get('max_iter')\n",
    "        for i in range(self._Y_train.shape[1]):\n",
    "            lasso = Lasso(alpha = alpha, max_iter = max_iter, fit_intercept=False)\n",
    "            lasso.fit(self._X_train,self._Y_train[:,i])\n",
    "            self._model['fund'+str(i+1)] = lasso\n",
    "    \n",
    "    def model_summary(self):\n",
    "        \"\"\"Function that provide summary of model result: prediction accuracy, different matrix \n",
    "            to measure the model, and hyper-parameters of the model\"\n",
    "\n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                dict {str: float/dataframe}\n",
    "                key is the staticial measure name\n",
    "                value is the statical measure, either a number or a matrix or a dataframe\n",
    "        \"\"\"\n",
    "        ### can add other performance measures later on \n",
    "        summary = dict()\n",
    "        summary['hyperparameter'] = self._hyperparameters\n",
    "        summary['rmse score'] = {}\n",
    "        i = 0\n",
    "        for fund in self._model.keys():\n",
    "            mse = mean_squared_error(y_true = self._Y_test[:,i], y_pred = self._Y_pred[fund])\n",
    "            rmse = math.sqrt(mse)\n",
    "            summary['rmse score'][fund] = rmse\n",
    "            i += 1  \n",
    "        return summary\n",
    "    \n",
    "class RidgeRegressionRiskGeneratorSQL(SimpleRegressionRiskGeneratorSQL):\n",
    "    def fit(self, **kwargs):\n",
    "        \"\"\"Function to execute training either based on the data that you load from file or passed in as argument.\n",
    "        When X, Y are passed in as argument, would train the model based on the training dataset passed in, and over write\n",
    "        the existing data cached in the risk generator obj. If you implement some new machine learning model rather than using\n",
    "        existing machine learning model by some python package, please seperate the implementation of the model in another class,\n",
    "        and initialize an instance of that model in your setup function rather than implement the model directly in the fit function,\n",
    "        so that we could seprate the business logics with the machine learning model maintaining logics, and those model could be reused\n",
    "        somewhere else too.\"\"\"\n",
    "        self._model = {} # dict to store all the regression models (one for each asset/fund)\n",
    "        alpha = self._hyperparameters.get('alpha')\n",
    "        for i in range(self._Y_train.shape[1]):\n",
    "            ridge = Ridge(alpha = alpha, fit_intercept=False)\n",
    "            ridge.fit(self._X_train,self._Y_train[:,i])\n",
    "            self._model['fund'+str(i+1)] = ridge\n",
    "    \n",
    "    def model_summary(self):\n",
    "        \"\"\"Function that provide summary of model result: prediction accuracy, different matrix \n",
    "            to measure the model, and hyper-parameters of the model\"\n",
    "\n",
    "        Parameters:\n",
    "            None\n",
    "\n",
    "            Return\n",
    "                dict {str: float/dataframe}\n",
    "                key is the staticial measure name\n",
    "                value is the statical measure, either a number or a matrix or a dataframe\n",
    "        \"\"\"\n",
    "        summary = dict()\n",
    "        summary['hyperparameter'] = self._hyperparameters\n",
    "        summary['rmse score'] = {}\n",
    "        i = 0\n",
    "        for fund in self._model.keys():\n",
    "            mse = mean_squared_error(y_true = self._Y_test[:,i], y_pred = self._Y_pred[fund])\n",
    "            rmse = math.sqrt(mse)\n",
    "            summary['rmse score'][fund] = rmse\n",
    "            i += 1  \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Changes to make:\n",
    "- factor data csv from morningstar: column name of factor is code for corresponding index so changed it to name of index directly in csv directly but should write a rule of correspondence to automatize this change (should not do it by hand)\n",
    "- display factor name or name of corresponding index in results?\n",
    "- different databases for each risk generator? (e.g. one for SimpleReg, one for LassoReg, etc...?)\n",
    "- when displaying results, show name of the fund instead of fund1, fund2,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test these new risk generator classes (integrating the SQLHandlerMixin class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['USER'] = 'qinyi'\n",
    "os.environ['PASSWORD'] = 'Lmz970802'\n",
    "username = os.getenv('USER')\n",
    "password = os.getenv('PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factors need to be defined consistent\n",
    "factors = ['morningstar msci emerging markets','s&p 500 pr', 'bbgbarc us treasury tr usd(1972)',\n",
    "           'libor 3 mon interbank eurodollar inv tr','bbgbarc us credit tr usd']\n",
    "# later will get list of factors from .txt file for example, once Miao shares with us the list of all the factors we should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0xa6d4dd35c0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c = sauma.core.Connection(username=username, password=password, schema='')\n",
    "#conn = c.connect()\n",
    "#sql = \"DROP DATABASE IF EXISTS Results\"\n",
    "#conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter schema(optional): \n",
      "\n",
      "morningstar msci emerging markets does not exist in schema Factors\n",
      "s&p 500 pr does not exist in schema Factors\n",
      "bbgbarc us treasury tr usd(1972) does not exist in schema Factors\n",
      "libor 3 mon interbank eurodollar inv tr does not exist in schema Factors\n",
      "bbgbarc us credit tr usd does not exist in schema Factors\n",
      "funds does not exist in schema Funds\n",
      "results does not exist in schema Results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fund1': array([ 2.10322011e-03,  8.60685540e-05,  8.01541329e-03, -1.21904875e-02,\n",
       "        -5.15615412e-03]),\n",
       " 'fund2': array([ 0.00210485,  0.00010685,  0.00810752, -0.01237828, -0.00522785]),\n",
       " 'fund3': array([-0.00077671,  0.00028673,  0.00166943, -0.00069375, -0.0005299 ]),\n",
       " 'fund4': array([-0.00077121,  0.0002782 ,  0.00167698, -0.0008211 , -0.00052513]),\n",
       " 'fund5': array([-0.00047566, -0.00127983, -0.00538609,  0.00468851,  0.00527788]),\n",
       " 'fund6': array([ 0.0013128 , -0.00244948, -0.00743549,  0.00200495,  0.00667327]),\n",
       " 'fund7': array([-0.00098656,  0.00041856,  0.00391079, -0.00240102, -0.00173188]),\n",
       " 'fund8': array([ 0.00271786, -0.00175246, -0.00355331, -0.00293746,  0.00298775]),\n",
       " 'fund9': array([ 0.00279185, -0.0009381 ,  0.0006826 , -0.00753939, -0.00019654]),\n",
       " 'fund10': array([ 0.0012385 , -0.00053869,  0.00176992, -0.00479297, -0.00059605]),\n",
       " 'fund11': array([-0.00082254, -0.0001694 , -0.00479665,  0.00599526,  0.00379979]),\n",
       " 'fund12': array([-2.48557189e-03,  7.47862462e-05,  1.84365673e-03,  2.05804857e-03,\n",
       "         7.85686381e-04]),\n",
       " 'fund13': array([ 0.00203201, -0.00205914, -0.00340948, -0.00265805,  0.00356106]),\n",
       " 'fund14': array([ 0.00319536, -0.00280783, -0.00560038, -0.00262785,  0.00487355]),\n",
       " 'fund15': array([ 0.00081391, -0.00158336, -0.00524024,  0.00263887,  0.00445773]),\n",
       " 'fund16': array([ 0.00254735, -0.00049463,  0.00019187, -0.00592994, -0.00024702]),\n",
       " 'fund17': array([ 0.00027158, -0.00089731, -0.00297204,  0.00090446,  0.00307161]),\n",
       " 'fund18': array([ 0.00256552, -0.00046884,  0.00035839, -0.00620541, -0.00038555])}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, we test class the SimpleRegressionRiskGeneratorSQL\n",
    "x = SimpleRegressionRiskGeneratorSQL(risk_generator_name = 'Regression', risk_factors = factors, username = username, password = password)\n",
    "x.set_up(hyperparameters = {}, data_path = {'index': {'morningstar msci emerging markets': 'Emerging Markets.csv',\n",
    "                                                      's&p 500 pr': 'S&P 500.csv',\n",
    "                                                      'bbgbarc us treasury tr usd(1972)': 'BBgBarc US Treasury.csv',\n",
    "                                                      'libor 3 mon interbank eurodollar inv tr': 'LIBOR 3 Mon Interbank Eurodollar Inv.csv',\n",
    "                                                      'bbgbarc us credit tr usd': 'BBgBarc US Credit.csv'}\n",
    "                                            ,'fund': 'Fund.csv'})\n",
    "x.update_raw_data()\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter schema(optional): \n",
      "\n",
      "morningstar msci emerging markets exists in schema Factors\n",
      "s&p 500 pr exists in schema Factors\n",
      "bbgbarc us treasury tr usd(1972) exists in schema Factors\n",
      "libor 3 mon interbank eurodollar inv tr exists in schema Factors\n",
      "bbgbarc us credit tr usd exists in schema Factors\n",
      "funds exists in schema Funds\n",
      "results exists in schema Results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fund1': array([ 2.10321939e-03,  8.60636510e-05,  8.01537976e-03, -1.21904556e-02,\n",
       "        -5.15613003e-03]),\n",
       " 'fund2': array([ 0.00210485,  0.00010685,  0.00810749, -0.01237825, -0.00522783]),\n",
       " 'fund3': array([-0.00077671,  0.00028673,  0.00166942, -0.00069375, -0.0005299 ]),\n",
       " 'fund4': array([-0.00077121,  0.0002782 ,  0.00167697, -0.00082109, -0.00052512]),\n",
       " 'fund5': array([-0.00047566, -0.00127982, -0.00538607,  0.00468849,  0.00527786]),\n",
       " 'fund6': array([ 0.0013128 , -0.00244948, -0.00743547,  0.00200494,  0.00667325]),\n",
       " 'fund7': array([-0.00098656,  0.00041856,  0.00391078, -0.00240101, -0.00173187]),\n",
       " 'fund8': array([ 0.00271786, -0.00175246, -0.0035533 , -0.00293746,  0.00298775]),\n",
       " 'fund9': array([ 0.00279185, -0.0009381 ,  0.00068259, -0.00753937, -0.00019653]),\n",
       " 'fund10': array([ 0.0012385 , -0.00053869,  0.00176991, -0.00479296, -0.00059604]),\n",
       " 'fund11': array([-0.00082254, -0.00016939, -0.00479663,  0.00599524,  0.00379978]),\n",
       " 'fund12': array([-2.48557172e-03,  7.47863409e-05,  1.84365761e-03,  2.05804751e-03,\n",
       "         7.85685678e-04]),\n",
       " 'fund13': array([ 0.00203201, -0.00205914, -0.00340948, -0.00265805,  0.00356106]),\n",
       " 'fund14': array([ 0.00319536, -0.00280783, -0.00560037, -0.00262785,  0.00487354]),\n",
       " 'fund15': array([ 0.00081391, -0.00158336, -0.00524023,  0.00263886,  0.00445772]),\n",
       " 'fund16': array([ 0.00254734, -0.00049463,  0.00019186, -0.00592993, -0.00024702]),\n",
       " 'fund17': array([ 0.00027158, -0.0008973 , -0.00297203,  0.00090445,  0.00307161]),\n",
       " 'fund18': array([ 0.00256552, -0.00046884,  0.00035839, -0.0062054 , -0.00038554])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test class RidgeRegressionRiskGeneratorSQL \n",
    "x = RidgeRegressionRiskGeneratorSQL(risk_generator_name = 'Ridge', risk_factors = factors, username = username, password = password)\n",
    "x.set_up(hyperparameters = {'alpha': 0.4}, data_path = {'index': {'morningstar msci emerging markets': 'Emerging Markets.csv',\n",
    "                                                      's&p 500 pr': 'S&P 500.csv',\n",
    "                                                      'bbgbarc us treasury tr usd(1972)': 'BBgBarc US Treasury.csv',\n",
    "                                                      'libor 3 mon interbank eurodollar inv tr': 'LIBOR 3 Mon Interbank Eurodollar Inv.csv',\n",
    "                                                      'bbgbarc us credit tr usd': 'BBgBarc US Credit.csv'}\n",
    "                                            ,'fund': 'Fund.csv'})\n",
    "x.update_raw_data()\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter schema(optional): \n",
      "\n",
      "morningstar msci emerging markets exists in schema Factors\n",
      "s&p 500 pr exists in schema Factors\n",
      "bbgbarc us treasury tr usd(1972) exists in schema Factors\n",
      "libor 3 mon interbank eurodollar inv tr exists in schema Factors\n",
      "bbgbarc us credit tr usd exists in schema Factors\n",
      "funds exists in schema Funds\n",
      "results exists in schema Results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fund1': array([ 2.06861665e-03, -5.56404773e-05,  7.02521235e-03, -1.12581494e-02,\n",
       "        -4.43056530e-03]),\n",
       " 'fund2': array([ 2.07024928e-03, -3.48551932e-05,  7.11733602e-03, -1.14459565e-02,\n",
       "        -4.50227291e-03]),\n",
       " 'fund3': array([-0.00077425,  0.0001691 ,  0.00092054, -0.        , -0.        ]),\n",
       " 'fund4': array([-0.0007662 ,  0.00016332,  0.00092133, -0.00010734,  0.        ]),\n",
       " 'fund5': array([-0.00044207, -0.0011063 , -0.00427622,  0.00365923,  0.00445405]),\n",
       " 'fund6': array([ 0.00132306, -0.00227495, -0.00633205,  0.00098831,  0.00587521]),\n",
       " 'fund7': array([-0.00099683,  0.00024405,  0.00280748, -0.00138449, -0.00093391]),\n",
       " 'fund8': array([ 0.0027155 , -0.00167484, -0.00317009, -0.00323049,  0.00268661]),\n",
       " 'fund9': array([ 2.78301099e-03, -9.81595541e-04,  2.63225394e-04, -7.10393637e-03,\n",
       "         8.00487996e-05]),\n",
       " 'fund10': array([ 0.00121142, -0.00065203,  0.00094417, -0.0040037 , -0.        ]),\n",
       " 'fund11': array([-0.0007888 , -0.        , -0.00370226,  0.0049785 ,  0.00298868]),\n",
       " 'fund12': array([-0.00245675,  0.00011609,  0.00216222,  0.00173914,  0.00054213]),\n",
       " 'fund13': array([ 0.00202965, -0.00198153, -0.00302631, -0.00295105,  0.00325995]),\n",
       " 'fund14': array([ 0.003193  , -0.0027302 , -0.00521714, -0.0029209 ,  0.00457239]),\n",
       " 'fund15': array([ 0.00082418, -0.00140884, -0.00413681,  0.00162224,  0.00365968]),\n",
       " 'fund16': array([ 2.51922730e-03, -5.34678539e-04, -1.21411599e-04, -5.61519986e-03,\n",
       "        -8.51083102e-06]),\n",
       " 'fund17': array([ 0.00027986, -0.0007378 , -0.00198025,  0.        ,  0.00235061]),\n",
       " 'fund18': array([ 2.53724827e-03, -5.35779318e-04, -1.27793825e-04, -5.73827699e-03,\n",
       "        -2.19864799e-05])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test class LassoRegressionRiskGeneratorSQL \n",
    "x = LassoRegressionRiskGeneratorSQL(risk_generator_name = 'Lasso', risk_factors = factors, username = username, password = password)\n",
    "x.set_up(hyperparameters = {'alpha': 0.6, 'max_iter': 100000}, data_path = {'index': {'morningstar msci emerging markets': 'Emerging Markets.csv',\n",
    "                                                      's&p 500 pr': 'S&P 500.csv',\n",
    "                                                      'bbgbarc us treasury tr usd(1972)': 'BBgBarc US Treasury.csv',\n",
    "                                                      'libor 3 mon interbank eurodollar inv tr': 'LIBOR 3 Mon Interbank Eurodollar Inv.csv',\n",
    "                                                      'bbgbarc us credit tr usd': 'BBgBarc US Credit.csv'}\n",
    "                                            ,'fund': 'Fund.csv'})\n",
    "x.update_raw_data()\n",
    "x.split_train_test_data()\n",
    "x.fit()\n",
    "x.predict()\n",
    "x.betas_fund()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk scenarios (with SQL): TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine the risk scenario by including the sql mixin class into the inheritance hierarchy, and redefine all the data \n",
    "#collection and publishing process using SQL instead of csv file\n",
    "\n",
    "class NaiveRiskScenarioSQL(NaiveRiskScenario, SQLHandlerMixin):\n",
    "    \"\"\"Inlcude SQL Operation in Risk Factors Shock Calculation \"\"\"\n",
    "    def setup_table_templates(self):\n",
    "        # take data from wrds for funds instead of morningstar\n",
    "        from table_templates import template_factor\n",
    "        json_factor = json.dumps(template_factor)\n",
    "        json_shocked_factor = json.dumps(template_factor)\n",
    "        self._templates = {'factor': json_factor, 'shocked_factor': json_shocked_factor}\n",
    "    \n",
    "    def check_table_exist_or_not(self, schema, table_name):\n",
    "        \"\"\"Please define this method to check whether a table under certain schema exist or not\"\"\"\n",
    "        c = self._conn.connect()\n",
    "        try:\n",
    "            self._conn.get_table(schema = schema, table_name = table_name) \n",
    "        except:\n",
    "            print(table_name + ' does not exist in schema ' + schema)\n",
    "        else: \n",
    "            print(table_name + ' exists in schema ' + schema)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def look_up_or_create_table(self, template, custom_table_name=None, custom_schema_name=None):\n",
    "        \"\"\"Please define this method to create a table based on the template if a table does not exist, do nothing if table \n",
    "        already exist, you may want to use self.check_table_exist_or_not here, if custom_table_name is none, \n",
    "        you should be able to find it in template\"\"\"\n",
    "        c = self._conn.connect()\n",
    "        if custom_table_name == None:\n",
    "            table_name = template.get('table_name')\n",
    "        else: \n",
    "            table_name = custom_table_name    \n",
    "        if custom_schema_name == None:\n",
    "            schema_name = template.get('schema')\n",
    "        else: \n",
    "            schema_name = custom_schema_name    \n",
    "        if not self.check_table_exist_or_not(schema = schema_name , table_name = table_name):\n",
    "                    template_custom = template\n",
    "                    template_custom['table_name'] = table_name\n",
    "                    template_custom['schema'] = schema_name\n",
    "                    template_custom = json.dumps(template_custom) # sauma.core package require a json obj as input\n",
    "                    self._conn.create_table(template_custom)  \n",
    "                    \n",
    "    def setup_tables(self):\n",
    "        \"\"\"setup all table based on the setup_table_templates\"\"\"\n",
    "        # first let us setup the tables for each risk factor\n",
    "        c = self._conn.connect()\n",
    "        sql = \"CREATE DATABASE IF NOT EXISTS factors\"\n",
    "        c.execute(sql)\n",
    "        template_factor = json.loads(self._templates.get('factor')) # json object back to a dict\n",
    "        for factor in self._risk_factors:\n",
    "            self.look_up_or_create_table(template = template_factor, custom_table_name = factor, custom_schema_name= None)\n",
    "        # then we create the table for shocked factors\n",
    "        c = self._conn.connect()\n",
    "        sql = \"CREATE DATABASE IF NOT EXISTS ShockedFactors\"\n",
    "        c.execute(sql)\n",
    "        template_shocked_factor = json.loads(self._templates.get('shocked_factor'))\n",
    "        for factor in self._risk_factors:\n",
    "            self.look_up_or_create_table(template = template_shocked_factor, custom_table_name = factor, custom_schema_name= 'ShockedFactors')\n",
    "    \n",
    "    \n",
    "    def __init__(self, scenario_name, risk_factors, username, password):\n",
    "        NaiveRiskScenario.__init__(self, scenario_name, risk_factors)\n",
    "        self.setup_connection(username, password)\n",
    "        self.setup_table_templates()\n",
    "        self.setup_tables()\n",
    "    \n",
    "    def update_raw_data(self):\n",
    "        \"\"\"assuming that your data source is the csv file containing all the raw data, load the raw data from csv, and update\n",
    "        the table which you already setup based on your template\"\"\"\n",
    "        c = self._conn.connect()\n",
    "        indiv_factors_data = {}\n",
    "        for factor, path in self._data_path.get('index').items(): # its a dict {factor name: path of csv file corresponding} factor name more covenient than index name\n",
    "            factor_data = pd.read_csv(path,sep=',', thousands=',')\n",
    "            factor_data.rename(columns={'Unnamed: 0': 'Date', \n",
    "                                        factor_data.columns[1]: factor}, inplace=True)\n",
    "            # transfo of data imported directly from Morningstar \n",
    "            self._conn.update_table(table_name = factor , dataframe = factor_data, schema = 'factors', index = False, if_exists = 'replace')\n",
    "            indiv_factors_data[factor] = self._conn.get_dataframe(table_name = factor, schema = 'factors') # indiv_factors_data is a dict\n",
    "        # merge all dataframes of individual factors on date column \n",
    "        red = partial(pd.merge, on='Date', how='outer')\n",
    "        self._factors_data = reduce(red, indiv_factors_data.values())\n",
    "\n",
    "    def publish_result(self):\n",
    "        \"\"\"upload the result data you have to sql, you would need to setup a json template to show how the result table would looks like too\"\"\"\n",
    "        for factor in self._risk_factors:\n",
    "            df = pd.DataFrame(self._factors_data_shocked[factor])\n",
    "            self._conn.update_table(table_name = factor , dataframe = df, schema = 'ShockedFactors', index = False, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCARiskScenarioSQL(NaiveRiskScenarioSQL):\n",
    "    def set_up(self, **kwargs):\n",
    "        \"\"\"Function to setup any private variable for the allocator\"\"\"\n",
    "        self._data_path = kwargs.get('data_path') # dict: {'fund': data_path for fund data, 'index': data_path for index data}\n",
    "        self._shocks = kwargs.get('shocks') # dict: {'factor1': shock1, ...} where shock1 = -0.1 to create a -10% shock\n",
    "        self._factor_choice = kwargs.get('factor_choice') # 'pc' to shock the principal components, 'factor' to shock specific risk factors \n",
    "        \n",
    "    def generate_scenario(self, **kwargs):\n",
    "        \"\"\"Function to generate scenario based on config you provide in **kwargs, you may have some machine learning based model\n",
    "        to derive the correlation of risk factors, and generate correlated risk scenarios, or you could assume that the movement\n",
    "        of risk factor are independent of each other, and apply different shock on the risk factors\"\"\"\n",
    "        if self._factor_choice == 'pc': # this means we shock the principal components\n",
    "            X = self._factors_data.to_numpy()[:,1:]# convert to numpy array and get rid of dates\n",
    "            pca = PCA(whiten = True).fit(X)\n",
    "            threshold = 0.85 # set a threshold to decide the number of principal components that should be kept\n",
    "            n_components = np.where(np.cumsum(pca.explained_variance_ratio_) >= threshold)[0][0] + 1\n",
    "            pca = PCA(n_components = n_components, whiten = True)\n",
    "            pc_X = pca.fit_transform(X)\n",
    "            pc_list = ['pc_'+str(i+1) for i in range(n_components)]\n",
    "            pc_shocked = pc_X.copy()\n",
    "            for i, pc in enumerate(pc_list):\n",
    "                shock = self._shocks.get(pc)\n",
    "                if shock is None:\n",
    "                    shock = 0.0\n",
    "                pc_shocked[:,i] = pc_shocked[:,i]*(1+shock)\n",
    "            X_shocked = pca.inverse_transform(pc_shocked)\n",
    "            self._factors_data_shocked = self._factors_data.copy()\n",
    "            self._factors_data_shocked.iloc[:,1:] = X_shocked\n",
    "            return self._factors_data_shocked   \n",
    "        elif self._factor_choice == 'factor': # this means we shock specific risk factors, just like naive risk secenario\n",
    "            return super().generate_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter schema(optional): \n",
      "\n",
      "morningstar msci emerging markets exists in schema Factors\n",
      "s&p 500 pr exists in schema Factors\n",
      "bbgbarc us treasury tr usd(1972) exists in schema Factors\n",
      "libor 3 mon interbank eurodollar inv tr exists in schema Factors\n",
      "bbgbarc us credit tr usd exists in schema Factors\n",
      "morningstar msci emerging markets exists in schema ShockedFactors\n",
      "s&p 500 pr exists in schema ShockedFactors\n",
      "bbgbarc us treasury tr usd(1972) exists in schema ShockedFactors\n",
      "libor 3 mon interbank eurodollar inv tr exists in schema ShockedFactors\n",
      "bbgbarc us credit tr usd exists in schema ShockedFactors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>morningstar msci emerging markets</th>\n",
       "      <th>s&amp;p 500 pr</th>\n",
       "      <th>bbgbarc us treasury tr usd(1972)</th>\n",
       "      <th>libor 3 mon interbank eurodollar inv tr</th>\n",
       "      <th>bbgbarc us credit tr usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/2020</td>\n",
       "      <td>3452.73</td>\n",
       "      <td>2690.400</td>\n",
       "      <td>2580.77</td>\n",
       "      <td>677.69</td>\n",
       "      <td>3392.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/2020</td>\n",
       "      <td>3505.42</td>\n",
       "      <td>2800.248</td>\n",
       "      <td>2577.19</td>\n",
       "      <td>677.83</td>\n",
       "      <td>3401.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/2020</td>\n",
       "      <td>3455.60</td>\n",
       "      <td>2616.896</td>\n",
       "      <td>2605.74</td>\n",
       "      <td>677.97</td>\n",
       "      <td>3445.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/2020</td>\n",
       "      <td>3292.46</td>\n",
       "      <td>2480.232</td>\n",
       "      <td>2576.30</td>\n",
       "      <td>678.09</td>\n",
       "      <td>3342.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/2020</td>\n",
       "      <td>3137.93</td>\n",
       "      <td>2435.448</td>\n",
       "      <td>2573.89</td>\n",
       "      <td>678.18</td>\n",
       "      <td>3282.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/2020</td>\n",
       "      <td>3051.36</td>\n",
       "      <td>2329.944</td>\n",
       "      <td>2580.42</td>\n",
       "      <td>678.14</td>\n",
       "      <td>3229.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3/2020</td>\n",
       "      <td>2934.74</td>\n",
       "      <td>2067.672</td>\n",
       "      <td>2564.12</td>\n",
       "      <td>677.61</td>\n",
       "      <td>3088.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/2020</td>\n",
       "      <td>3220.36</td>\n",
       "      <td>2363.376</td>\n",
       "      <td>2492.04</td>\n",
       "      <td>677.07</td>\n",
       "      <td>3307.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/2020</td>\n",
       "      <td>3331.68</td>\n",
       "      <td>2580.416</td>\n",
       "      <td>2427.69</td>\n",
       "      <td>676.37</td>\n",
       "      <td>3263.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/2019</td>\n",
       "      <td>3339.77</td>\n",
       "      <td>2584.624</td>\n",
       "      <td>2369.78</td>\n",
       "      <td>675.58</td>\n",
       "      <td>3188.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11/2019</td>\n",
       "      <td>3258.57</td>\n",
       "      <td>2512.784</td>\n",
       "      <td>2383.16</td>\n",
       "      <td>674.79</td>\n",
       "      <td>3179.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10/2019</td>\n",
       "      <td>3279.20</td>\n",
       "      <td>2430.048</td>\n",
       "      <td>2390.35</td>\n",
       "      <td>674.01</td>\n",
       "      <td>3173.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9/2019</td>\n",
       "      <td>3219.91</td>\n",
       "      <td>2381.392</td>\n",
       "      <td>2388.72</td>\n",
       "      <td>673.13</td>\n",
       "      <td>3155.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8/2019</td>\n",
       "      <td>3151.68</td>\n",
       "      <td>2341.168</td>\n",
       "      <td>2409.10</td>\n",
       "      <td>672.22</td>\n",
       "      <td>3176.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7/2019</td>\n",
       "      <td>3197.90</td>\n",
       "      <td>2384.304</td>\n",
       "      <td>2329.89</td>\n",
       "      <td>671.24</td>\n",
       "      <td>3079.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6/2019</td>\n",
       "      <td>3214.75</td>\n",
       "      <td>2353.408</td>\n",
       "      <td>2332.63</td>\n",
       "      <td>670.23</td>\n",
       "      <td>3064.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5/2019</td>\n",
       "      <td>3127.54</td>\n",
       "      <td>2201.648</td>\n",
       "      <td>2311.31</td>\n",
       "      <td>669.12</td>\n",
       "      <td>2996.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/2019</td>\n",
       "      <td>3199.95</td>\n",
       "      <td>2356.664</td>\n",
       "      <td>2258.24</td>\n",
       "      <td>667.98</td>\n",
       "      <td>2952.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3/2019</td>\n",
       "      <td>3166.51</td>\n",
       "      <td>2267.520</td>\n",
       "      <td>2264.52</td>\n",
       "      <td>666.82</td>\n",
       "      <td>2938.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2/2019</td>\n",
       "      <td>3111.31</td>\n",
       "      <td>2227.592</td>\n",
       "      <td>2222.10</td>\n",
       "      <td>665.66</td>\n",
       "      <td>2868.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/2019</td>\n",
       "      <td>3053.94</td>\n",
       "      <td>2163.280</td>\n",
       "      <td>2228.14</td>\n",
       "      <td>664.44</td>\n",
       "      <td>2862.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12/2018</td>\n",
       "      <td>2947.36</td>\n",
       "      <td>2005.480</td>\n",
       "      <td>2217.70</td>\n",
       "      <td>663.17</td>\n",
       "      <td>2801.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11/2018</td>\n",
       "      <td>2975.80</td>\n",
       "      <td>2208.136</td>\n",
       "      <td>2170.99</td>\n",
       "      <td>661.95</td>\n",
       "      <td>2760.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10/2018</td>\n",
       "      <td>2938.21</td>\n",
       "      <td>2169.392</td>\n",
       "      <td>2151.89</td>\n",
       "      <td>660.83</td>\n",
       "      <td>2762.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9/2018</td>\n",
       "      <td>3068.91</td>\n",
       "      <td>2331.184</td>\n",
       "      <td>2162.22</td>\n",
       "      <td>659.79</td>\n",
       "      <td>2801.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8/2018</td>\n",
       "      <td>3105.22</td>\n",
       "      <td>2321.216</td>\n",
       "      <td>2182.60</td>\n",
       "      <td>658.80</td>\n",
       "      <td>2811.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7/2018</td>\n",
       "      <td>3204.68</td>\n",
       "      <td>2253.032</td>\n",
       "      <td>2166.03</td>\n",
       "      <td>657.80</td>\n",
       "      <td>2796.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6/2018</td>\n",
       "      <td>3229.15</td>\n",
       "      <td>2174.696</td>\n",
       "      <td>2175.13</td>\n",
       "      <td>656.80</td>\n",
       "      <td>2776.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5/2018</td>\n",
       "      <td>3285.50</td>\n",
       "      <td>2164.216</td>\n",
       "      <td>2174.68</td>\n",
       "      <td>655.81</td>\n",
       "      <td>2789.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4/2018</td>\n",
       "      <td>3352.32</td>\n",
       "      <td>2118.440</td>\n",
       "      <td>2155.33</td>\n",
       "      <td>654.81</td>\n",
       "      <td>2775.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3/2003</td>\n",
       "      <td>1092.68</td>\n",
       "      <td>678.544</td>\n",
       "      <td>1311.12</td>\n",
       "      <td>551.30</td>\n",
       "      <td>1365.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2/2003</td>\n",
       "      <td>1094.94</td>\n",
       "      <td>672.920</td>\n",
       "      <td>1316.60</td>\n",
       "      <td>550.94</td>\n",
       "      <td>1364.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1/2003</td>\n",
       "      <td>1085.16</td>\n",
       "      <td>684.560</td>\n",
       "      <td>1294.33</td>\n",
       "      <td>550.56</td>\n",
       "      <td>1337.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>12/2002</td>\n",
       "      <td>1074.19</td>\n",
       "      <td>703.856</td>\n",
       "      <td>1298.28</td>\n",
       "      <td>550.17</td>\n",
       "      <td>1333.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>11/2002</td>\n",
       "      <td>1075.03</td>\n",
       "      <td>749.048</td>\n",
       "      <td>1265.40</td>\n",
       "      <td>549.77</td>\n",
       "      <td>1295.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>10/2002</td>\n",
       "      <td>1054.97</td>\n",
       "      <td>708.608</td>\n",
       "      <td>1278.06</td>\n",
       "      <td>549.35</td>\n",
       "      <td>1278.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>9/2002</td>\n",
       "      <td>1047.54</td>\n",
       "      <td>652.224</td>\n",
       "      <td>1292.36</td>\n",
       "      <td>548.80</td>\n",
       "      <td>1293.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>8/2002</td>\n",
       "      <td>1054.25</td>\n",
       "      <td>732.856</td>\n",
       "      <td>1258.43</td>\n",
       "      <td>548.20</td>\n",
       "      <td>1269.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>7/2002</td>\n",
       "      <td>1046.67</td>\n",
       "      <td>729.296</td>\n",
       "      <td>1231.80</td>\n",
       "      <td>547.61</td>\n",
       "      <td>1237.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>6/2002</td>\n",
       "      <td>1063.85</td>\n",
       "      <td>791.848</td>\n",
       "      <td>1203.29</td>\n",
       "      <td>547.01</td>\n",
       "      <td>1238.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5/2002</td>\n",
       "      <td>1089.02</td>\n",
       "      <td>853.712</td>\n",
       "      <td>1186.54</td>\n",
       "      <td>546.40</td>\n",
       "      <td>1236.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>4/2002</td>\n",
       "      <td>1089.97</td>\n",
       "      <td>861.536</td>\n",
       "      <td>1179.93</td>\n",
       "      <td>545.77</td>\n",
       "      <td>1219.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3/2002</td>\n",
       "      <td>1076.79</td>\n",
       "      <td>917.912</td>\n",
       "      <td>1151.29</td>\n",
       "      <td>545.13</td>\n",
       "      <td>1203.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2/2002</td>\n",
       "      <td>1049.04</td>\n",
       "      <td>885.384</td>\n",
       "      <td>1179.67</td>\n",
       "      <td>544.44</td>\n",
       "      <td>1225.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1/2002</td>\n",
       "      <td>1026.68</td>\n",
       "      <td>904.160</td>\n",
       "      <td>1169.14</td>\n",
       "      <td>543.80</td>\n",
       "      <td>1216.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12/2001</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>918.464</td>\n",
       "      <td>1161.32</td>\n",
       "      <td>543.19</td>\n",
       "      <td>1206.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>11/2001</td>\n",
       "      <td>974.49</td>\n",
       "      <td>911.560</td>\n",
       "      <td>1172.74</td>\n",
       "      <td>542.57</td>\n",
       "      <td>1214.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>10/2001</td>\n",
       "      <td>937.96</td>\n",
       "      <td>847.824</td>\n",
       "      <td>1202.51</td>\n",
       "      <td>541.86</td>\n",
       "      <td>1225.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>9/2001</td>\n",
       "      <td>918.11</td>\n",
       "      <td>832.752</td>\n",
       "      <td>1170.10</td>\n",
       "      <td>541.09</td>\n",
       "      <td>1195.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>8/2001</td>\n",
       "      <td>954.22</td>\n",
       "      <td>906.864</td>\n",
       "      <td>1151.82</td>\n",
       "      <td>540.15</td>\n",
       "      <td>1197.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>7/2001</td>\n",
       "      <td>945.18</td>\n",
       "      <td>968.984</td>\n",
       "      <td>1136.76</td>\n",
       "      <td>538.82</td>\n",
       "      <td>1181.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>6/2001</td>\n",
       "      <td>959.79</td>\n",
       "      <td>979.536</td>\n",
       "      <td>1109.09</td>\n",
       "      <td>537.42</td>\n",
       "      <td>1151.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5/2001</td>\n",
       "      <td>948.41</td>\n",
       "      <td>1004.656</td>\n",
       "      <td>1103.17</td>\n",
       "      <td>535.97</td>\n",
       "      <td>1145.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>4/2001</td>\n",
       "      <td>930.13</td>\n",
       "      <td>999.568</td>\n",
       "      <td>1099.74</td>\n",
       "      <td>534.44</td>\n",
       "      <td>1135.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3/2001</td>\n",
       "      <td>923.56</td>\n",
       "      <td>928.264</td>\n",
       "      <td>1113.58</td>\n",
       "      <td>532.76</td>\n",
       "      <td>1139.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2/2001</td>\n",
       "      <td>932.91</td>\n",
       "      <td>991.952</td>\n",
       "      <td>1110.02</td>\n",
       "      <td>530.86</td>\n",
       "      <td>1132.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1/2001</td>\n",
       "      <td>939.60</td>\n",
       "      <td>1092.808</td>\n",
       "      <td>1096.76</td>\n",
       "      <td>528.88</td>\n",
       "      <td>1122.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>12/2000</td>\n",
       "      <td>893.87</td>\n",
       "      <td>1056.224</td>\n",
       "      <td>1087.91</td>\n",
       "      <td>526.72</td>\n",
       "      <td>1092.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>11/2000</td>\n",
       "      <td>888.02</td>\n",
       "      <td>1051.960</td>\n",
       "      <td>1067.54</td>\n",
       "      <td>524.21</td>\n",
       "      <td>1071.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10/2000</td>\n",
       "      <td>902.76</td>\n",
       "      <td>1143.520</td>\n",
       "      <td>1046.10</td>\n",
       "      <td>521.57</td>\n",
       "      <td>1058.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  morningstar msci emerging markets  s&p 500 pr  \\\n",
       "0     9/2020                            3452.73    2690.400   \n",
       "1     8/2020                            3505.42    2800.248   \n",
       "2     7/2020                            3455.60    2616.896   \n",
       "3     6/2020                            3292.46    2480.232   \n",
       "4     5/2020                            3137.93    2435.448   \n",
       "5     4/2020                            3051.36    2329.944   \n",
       "6     3/2020                            2934.74    2067.672   \n",
       "7     2/2020                            3220.36    2363.376   \n",
       "8     1/2020                            3331.68    2580.416   \n",
       "9    12/2019                            3339.77    2584.624   \n",
       "10   11/2019                            3258.57    2512.784   \n",
       "11   10/2019                            3279.20    2430.048   \n",
       "12    9/2019                            3219.91    2381.392   \n",
       "13    8/2019                            3151.68    2341.168   \n",
       "14    7/2019                            3197.90    2384.304   \n",
       "15    6/2019                            3214.75    2353.408   \n",
       "16    5/2019                            3127.54    2201.648   \n",
       "17    4/2019                            3199.95    2356.664   \n",
       "18    3/2019                            3166.51    2267.520   \n",
       "19    2/2019                            3111.31    2227.592   \n",
       "20    1/2019                            3053.94    2163.280   \n",
       "21   12/2018                            2947.36    2005.480   \n",
       "22   11/2018                            2975.80    2208.136   \n",
       "23   10/2018                            2938.21    2169.392   \n",
       "24    9/2018                            3068.91    2331.184   \n",
       "25    8/2018                            3105.22    2321.216   \n",
       "26    7/2018                            3204.68    2253.032   \n",
       "27    6/2018                            3229.15    2174.696   \n",
       "28    5/2018                            3285.50    2164.216   \n",
       "29    4/2018                            3352.32    2118.440   \n",
       "..       ...                                ...         ...   \n",
       "210   3/2003                            1092.68     678.544   \n",
       "211   2/2003                            1094.94     672.920   \n",
       "212   1/2003                            1085.16     684.560   \n",
       "213  12/2002                            1074.19     703.856   \n",
       "214  11/2002                            1075.03     749.048   \n",
       "215  10/2002                            1054.97     708.608   \n",
       "216   9/2002                            1047.54     652.224   \n",
       "217   8/2002                            1054.25     732.856   \n",
       "218   7/2002                            1046.67     729.296   \n",
       "219   6/2002                            1063.85     791.848   \n",
       "220   5/2002                            1089.02     853.712   \n",
       "221   4/2002                            1089.97     861.536   \n",
       "222   3/2002                            1076.79     917.912   \n",
       "223   2/2002                            1049.04     885.384   \n",
       "224   1/2002                            1026.68     904.160   \n",
       "225  12/2001                            1000.00     918.464   \n",
       "226  11/2001                             974.49     911.560   \n",
       "227  10/2001                             937.96     847.824   \n",
       "228   9/2001                             918.11     832.752   \n",
       "229   8/2001                             954.22     906.864   \n",
       "230   7/2001                             945.18     968.984   \n",
       "231   6/2001                             959.79     979.536   \n",
       "232   5/2001                             948.41    1004.656   \n",
       "233   4/2001                             930.13     999.568   \n",
       "234   3/2001                             923.56     928.264   \n",
       "235   2/2001                             932.91     991.952   \n",
       "236   1/2001                             939.60    1092.808   \n",
       "237  12/2000                             893.87    1056.224   \n",
       "238  11/2000                             888.02    1051.960   \n",
       "239  10/2000                             902.76    1143.520   \n",
       "\n",
       "     bbgbarc us treasury tr usd(1972)  \\\n",
       "0                             2580.77   \n",
       "1                             2577.19   \n",
       "2                             2605.74   \n",
       "3                             2576.30   \n",
       "4                             2573.89   \n",
       "5                             2580.42   \n",
       "6                             2564.12   \n",
       "7                             2492.04   \n",
       "8                             2427.69   \n",
       "9                             2369.78   \n",
       "10                            2383.16   \n",
       "11                            2390.35   \n",
       "12                            2388.72   \n",
       "13                            2409.10   \n",
       "14                            2329.89   \n",
       "15                            2332.63   \n",
       "16                            2311.31   \n",
       "17                            2258.24   \n",
       "18                            2264.52   \n",
       "19                            2222.10   \n",
       "20                            2228.14   \n",
       "21                            2217.70   \n",
       "22                            2170.99   \n",
       "23                            2151.89   \n",
       "24                            2162.22   \n",
       "25                            2182.60   \n",
       "26                            2166.03   \n",
       "27                            2175.13   \n",
       "28                            2174.68   \n",
       "29                            2155.33   \n",
       "..                                ...   \n",
       "210                           1311.12   \n",
       "211                           1316.60   \n",
       "212                           1294.33   \n",
       "213                           1298.28   \n",
       "214                           1265.40   \n",
       "215                           1278.06   \n",
       "216                           1292.36   \n",
       "217                           1258.43   \n",
       "218                           1231.80   \n",
       "219                           1203.29   \n",
       "220                           1186.54   \n",
       "221                           1179.93   \n",
       "222                           1151.29   \n",
       "223                           1179.67   \n",
       "224                           1169.14   \n",
       "225                           1161.32   \n",
       "226                           1172.74   \n",
       "227                           1202.51   \n",
       "228                           1170.10   \n",
       "229                           1151.82   \n",
       "230                           1136.76   \n",
       "231                           1109.09   \n",
       "232                           1103.17   \n",
       "233                           1099.74   \n",
       "234                           1113.58   \n",
       "235                           1110.02   \n",
       "236                           1096.76   \n",
       "237                           1087.91   \n",
       "238                           1067.54   \n",
       "239                           1046.10   \n",
       "\n",
       "     libor 3 mon interbank eurodollar inv tr  bbgbarc us credit tr usd  \n",
       "0                                     677.69                   3392.20  \n",
       "1                                     677.83                   3401.53  \n",
       "2                                     677.97                   3445.17  \n",
       "3                                     678.09                   3342.11  \n",
       "4                                     678.18                   3282.14  \n",
       "5                                     678.14                   3229.64  \n",
       "6                                     677.61                   3088.31  \n",
       "7                                     677.07                   3307.52  \n",
       "8                                     676.37                   3263.14  \n",
       "9                                     675.58                   3188.55  \n",
       "10                                    674.79                   3179.41  \n",
       "11                                    674.01                   3173.39  \n",
       "12                                    673.13                   3155.41  \n",
       "13                                    672.22                   3176.17  \n",
       "14                                    671.24                   3079.88  \n",
       "15                                    670.23                   3064.07  \n",
       "16                                    669.12                   2996.37  \n",
       "17                                    667.98                   2952.99  \n",
       "18                                    666.82                   2938.57  \n",
       "19                                    665.66                   2868.70  \n",
       "20                                    664.44                   2862.54  \n",
       "21                                    663.17                   2801.99  \n",
       "22                                    661.95                   2760.49  \n",
       "23                                    660.83                   2762.36  \n",
       "24                                    659.79                   2801.59  \n",
       "25                                    658.80                   2811.06  \n",
       "26                                    657.80                   2796.80  \n",
       "27                                    656.80                   2776.88  \n",
       "28                                    655.81                   2789.91  \n",
       "29                                    654.81                   2775.90  \n",
       "..                                       ...                       ...  \n",
       "210                                   551.30                   1365.42  \n",
       "211                                   550.94                   1364.44  \n",
       "212                                   550.56                   1337.69  \n",
       "213                                   550.17                   1333.36  \n",
       "214                                   549.77                   1295.18  \n",
       "215                                   549.35                   1278.60  \n",
       "216                                   548.80                   1293.58  \n",
       "217                                   548.20                   1269.47  \n",
       "218                                   547.61                   1237.42  \n",
       "219                                   547.01                   1238.06  \n",
       "220                                   546.40                   1236.05  \n",
       "221                                   545.77                   1219.90  \n",
       "222                                   545.13                   1203.14  \n",
       "223                                   544.44                   1225.78  \n",
       "224                                   543.80                   1216.59  \n",
       "225                                   543.19                   1206.39  \n",
       "226                                   542.57                   1214.72  \n",
       "227                                   541.86                   1225.37  \n",
       "228                                   541.09                   1195.70  \n",
       "229                                   540.15                   1197.46  \n",
       "230                                   538.82                   1181.62  \n",
       "231                                   537.42                   1151.55  \n",
       "232                                   535.97                   1145.74  \n",
       "233                                   534.44                   1135.33  \n",
       "234                                   532.76                   1139.44  \n",
       "235                                   530.86                   1132.43  \n",
       "236                                   528.88                   1122.63  \n",
       "237                                   526.72                   1092.73  \n",
       "238                                   524.21                   1071.93  \n",
       "239                                   521.57                   1058.22  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = NaiveRiskScenarioSQL(scenario_name = 'Naive', risk_factors = factors, username = username, password = password)\n",
    "x.set_up(data_path = {'index': {'morningstar msci emerging markets': 'Emerging Markets.csv',\n",
    "                                                      's&p 500 pr': 'S&P 500.csv',\n",
    "                                                      'bbgbarc us treasury tr usd(1972)': 'BBgBarc US Treasury.csv',\n",
    "                                                      'libor 3 mon interbank eurodollar inv tr': 'LIBOR 3 Mon Interbank Eurodollar Inv.csv',\n",
    "                                                      'bbgbarc us credit tr usd': 'BBgBarc US Credit.csv'}}, shocks = {'s&p 500 pr': -0.2})\n",
    "x.update_raw_data()\n",
    "x.generate_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter schema(optional): \n",
      "\n",
      "morningstar msci emerging markets exists in schema Factors\n",
      "s&p 500 pr exists in schema Factors\n",
      "bbgbarc us treasury tr usd(1972) exists in schema Factors\n",
      "libor 3 mon interbank eurodollar inv tr exists in schema Factors\n",
      "bbgbarc us credit tr usd exists in schema Factors\n",
      "morningstar msci emerging markets exists in schema ShockedFactors\n",
      "s&p 500 pr exists in schema ShockedFactors\n",
      "bbgbarc us treasury tr usd(1972) exists in schema ShockedFactors\n",
      "libor 3 mon interbank eurodollar inv tr exists in schema ShockedFactors\n",
      "bbgbarc us credit tr usd exists in schema ShockedFactors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>morningstar msci emerging markets</th>\n",
       "      <th>s&amp;p 500 pr</th>\n",
       "      <th>bbgbarc us treasury tr usd(1972)</th>\n",
       "      <th>libor 3 mon interbank eurodollar inv tr</th>\n",
       "      <th>bbgbarc us credit tr usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/2020</td>\n",
       "      <td>3404.811278</td>\n",
       "      <td>2720.314412</td>\n",
       "      <td>2472.158183</td>\n",
       "      <td>688.342291</td>\n",
       "      <td>3168.113801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/2020</td>\n",
       "      <td>3454.425614</td>\n",
       "      <td>2764.692906</td>\n",
       "      <td>2500.029580</td>\n",
       "      <td>691.086594</td>\n",
       "      <td>3212.897777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/2020</td>\n",
       "      <td>3400.050169</td>\n",
       "      <td>2716.055747</td>\n",
       "      <td>2469.483578</td>\n",
       "      <td>688.078941</td>\n",
       "      <td>3163.816224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/2020</td>\n",
       "      <td>3284.010200</td>\n",
       "      <td>2612.261573</td>\n",
       "      <td>2404.296854</td>\n",
       "      <td>681.660455</td>\n",
       "      <td>3059.073689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/2020</td>\n",
       "      <td>3213.081920</td>\n",
       "      <td>2548.818413</td>\n",
       "      <td>2364.452115</td>\n",
       "      <td>677.737220</td>\n",
       "      <td>2995.050853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/2020</td>\n",
       "      <td>3145.379162</td>\n",
       "      <td>2488.260384</td>\n",
       "      <td>2326.419350</td>\n",
       "      <td>673.992397</td>\n",
       "      <td>2933.939509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3/2020</td>\n",
       "      <td>2996.308271</td>\n",
       "      <td>2354.921068</td>\n",
       "      <td>2242.677143</td>\n",
       "      <td>665.746881</td>\n",
       "      <td>2799.381880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/2020</td>\n",
       "      <td>3207.277138</td>\n",
       "      <td>2543.626215</td>\n",
       "      <td>2361.191216</td>\n",
       "      <td>677.416142</td>\n",
       "      <td>2989.811214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/2020</td>\n",
       "      <td>3283.021423</td>\n",
       "      <td>2611.377142</td>\n",
       "      <td>2403.741397</td>\n",
       "      <td>681.605764</td>\n",
       "      <td>3058.181177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/2019</td>\n",
       "      <td>3259.265705</td>\n",
       "      <td>2590.128385</td>\n",
       "      <td>2390.396363</td>\n",
       "      <td>680.291770</td>\n",
       "      <td>3036.738272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11/2019</td>\n",
       "      <td>3215.003944</td>\n",
       "      <td>2550.537605</td>\n",
       "      <td>2365.531834</td>\n",
       "      <td>677.843532</td>\n",
       "      <td>2996.785753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10/2019</td>\n",
       "      <td>3195.010168</td>\n",
       "      <td>2532.653788</td>\n",
       "      <td>2354.300111</td>\n",
       "      <td>676.737622</td>\n",
       "      <td>2978.738533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9/2019</td>\n",
       "      <td>3159.315824</td>\n",
       "      <td>2500.726298</td>\n",
       "      <td>2334.248422</td>\n",
       "      <td>674.763271</td>\n",
       "      <td>2946.519323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8/2019</td>\n",
       "      <td>3136.662340</td>\n",
       "      <td>2480.463455</td>\n",
       "      <td>2321.522579</td>\n",
       "      <td>673.510246</td>\n",
       "      <td>2926.071340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7/2019</td>\n",
       "      <td>3126.567300</td>\n",
       "      <td>2471.433753</td>\n",
       "      <td>2315.851580</td>\n",
       "      <td>672.951862</td>\n",
       "      <td>2916.959134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6/2019</td>\n",
       "      <td>3118.254473</td>\n",
       "      <td>2463.998186</td>\n",
       "      <td>2311.181758</td>\n",
       "      <td>672.492057</td>\n",
       "      <td>2909.455629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5/2019</td>\n",
       "      <td>3028.248430</td>\n",
       "      <td>2383.490555</td>\n",
       "      <td>2260.619877</td>\n",
       "      <td>667.513578</td>\n",
       "      <td>2828.212405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4/2019</td>\n",
       "      <td>3076.436776</td>\n",
       "      <td>2426.593545</td>\n",
       "      <td>2287.690209</td>\n",
       "      <td>670.179006</td>\n",
       "      <td>2871.709224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3/2019</td>\n",
       "      <td>3037.530501</td>\n",
       "      <td>2391.793082</td>\n",
       "      <td>2265.834183</td>\n",
       "      <td>668.026995</td>\n",
       "      <td>2836.590791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2/2019</td>\n",
       "      <td>2986.586204</td>\n",
       "      <td>2346.224979</td>\n",
       "      <td>2237.215666</td>\n",
       "      <td>665.209127</td>\n",
       "      <td>2790.606335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/2019</td>\n",
       "      <td>2950.721241</td>\n",
       "      <td>2314.144875</td>\n",
       "      <td>2217.068130</td>\n",
       "      <td>663.225339</td>\n",
       "      <td>2758.233118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12/2018</td>\n",
       "      <td>2857.015488</td>\n",
       "      <td>2230.327969</td>\n",
       "      <td>2164.427896</td>\n",
       "      <td>658.042220</td>\n",
       "      <td>2673.650381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11/2018</td>\n",
       "      <td>2909.174823</td>\n",
       "      <td>2276.982885</td>\n",
       "      <td>2193.728974</td>\n",
       "      <td>660.927294</td>\n",
       "      <td>2720.731581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10/2018</td>\n",
       "      <td>2884.627044</td>\n",
       "      <td>2255.025654</td>\n",
       "      <td>2179.938990</td>\n",
       "      <td>659.569490</td>\n",
       "      <td>2698.573728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9/2018</td>\n",
       "      <td>2980.828000</td>\n",
       "      <td>2341.074443</td>\n",
       "      <td>2233.980931</td>\n",
       "      <td>664.890626</td>\n",
       "      <td>2785.408739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8/2018</td>\n",
       "      <td>2993.129289</td>\n",
       "      <td>2352.077566</td>\n",
       "      <td>2240.891315</td>\n",
       "      <td>665.571043</td>\n",
       "      <td>2796.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7/2018</td>\n",
       "      <td>2993.399011</td>\n",
       "      <td>2352.318824</td>\n",
       "      <td>2241.042834</td>\n",
       "      <td>665.585962</td>\n",
       "      <td>2796.755860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6/2018</td>\n",
       "      <td>2972.661720</td>\n",
       "      <td>2333.769957</td>\n",
       "      <td>2229.393434</td>\n",
       "      <td>664.438926</td>\n",
       "      <td>2778.037513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5/2018</td>\n",
       "      <td>2987.957266</td>\n",
       "      <td>2347.451352</td>\n",
       "      <td>2237.985874</td>\n",
       "      <td>665.284965</td>\n",
       "      <td>2791.843913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4/2018</td>\n",
       "      <td>2985.793843</td>\n",
       "      <td>2345.516237</td>\n",
       "      <td>2236.770548</td>\n",
       "      <td>665.165300</td>\n",
       "      <td>2789.891117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3/2003</td>\n",
       "      <td>1452.403904</td>\n",
       "      <td>973.946216</td>\n",
       "      <td>1375.371948</td>\n",
       "      <td>580.349343</td>\n",
       "      <td>1405.789146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2/2003</td>\n",
       "      <td>1451.898245</td>\n",
       "      <td>973.493920</td>\n",
       "      <td>1375.087889</td>\n",
       "      <td>580.321373</td>\n",
       "      <td>1405.332718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1/2003</td>\n",
       "      <td>1442.777974</td>\n",
       "      <td>965.336118</td>\n",
       "      <td>1369.964477</td>\n",
       "      <td>579.816906</td>\n",
       "      <td>1397.100379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>12/2002</td>\n",
       "      <td>1445.203370</td>\n",
       "      <td>967.505560</td>\n",
       "      <td>1371.326970</td>\n",
       "      <td>579.951062</td>\n",
       "      <td>1399.289643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>11/2002</td>\n",
       "      <td>1444.770537</td>\n",
       "      <td>967.118405</td>\n",
       "      <td>1371.083821</td>\n",
       "      <td>579.927120</td>\n",
       "      <td>1398.898950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>10/2002</td>\n",
       "      <td>1424.820785</td>\n",
       "      <td>949.273967</td>\n",
       "      <td>1359.876829</td>\n",
       "      <td>578.823646</td>\n",
       "      <td>1380.891468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>9/2002</td>\n",
       "      <td>1411.472004</td>\n",
       "      <td>937.333893</td>\n",
       "      <td>1352.378005</td>\n",
       "      <td>578.085288</td>\n",
       "      <td>1368.842299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>8/2002</td>\n",
       "      <td>1426.745948</td>\n",
       "      <td>950.995965</td>\n",
       "      <td>1360.958310</td>\n",
       "      <td>578.930132</td>\n",
       "      <td>1382.629201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>7/2002</td>\n",
       "      <td>1411.615104</td>\n",
       "      <td>937.461892</td>\n",
       "      <td>1352.458393</td>\n",
       "      <td>578.093204</td>\n",
       "      <td>1368.971467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>6/2002</td>\n",
       "      <td>1431.154335</td>\n",
       "      <td>954.939132</td>\n",
       "      <td>1363.434770</td>\n",
       "      <td>579.173971</td>\n",
       "      <td>1386.608396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>5/2002</td>\n",
       "      <td>1453.811922</td>\n",
       "      <td>975.205644</td>\n",
       "      <td>1376.162918</td>\n",
       "      <td>580.427224</td>\n",
       "      <td>1407.060082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>4/2002</td>\n",
       "      <td>1451.458985</td>\n",
       "      <td>973.101015</td>\n",
       "      <td>1374.841130</td>\n",
       "      <td>580.297077</td>\n",
       "      <td>1404.936223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3/2002</td>\n",
       "      <td>1456.531671</td>\n",
       "      <td>977.638376</td>\n",
       "      <td>1377.690767</td>\n",
       "      <td>580.577661</td>\n",
       "      <td>1409.515042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2/2002</td>\n",
       "      <td>1448.956022</td>\n",
       "      <td>970.862192</td>\n",
       "      <td>1373.435063</td>\n",
       "      <td>580.158631</td>\n",
       "      <td>1402.676944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1/2002</td>\n",
       "      <td>1444.698180</td>\n",
       "      <td>967.053683</td>\n",
       "      <td>1371.043173</td>\n",
       "      <td>579.923118</td>\n",
       "      <td>1398.833637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12/2001</td>\n",
       "      <td>1438.065617</td>\n",
       "      <td>961.121060</td>\n",
       "      <td>1367.317258</td>\n",
       "      <td>579.556253</td>\n",
       "      <td>1392.846808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>11/2001</td>\n",
       "      <td>1432.794254</td>\n",
       "      <td>956.405988</td>\n",
       "      <td>1364.356012</td>\n",
       "      <td>579.264680</td>\n",
       "      <td>1388.088655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>10/2001</td>\n",
       "      <td>1410.569433</td>\n",
       "      <td>936.526571</td>\n",
       "      <td>1351.870976</td>\n",
       "      <td>578.035365</td>\n",
       "      <td>1368.027601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>9/2001</td>\n",
       "      <td>1388.279822</td>\n",
       "      <td>916.589201</td>\n",
       "      <td>1339.349542</td>\n",
       "      <td>576.802466</td>\n",
       "      <td>1347.908064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>8/2001</td>\n",
       "      <td>1418.344203</td>\n",
       "      <td>943.480864</td>\n",
       "      <td>1356.238538</td>\n",
       "      <td>578.465408</td>\n",
       "      <td>1375.045434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>7/2001</td>\n",
       "      <td>1428.593899</td>\n",
       "      <td>952.648900</td>\n",
       "      <td>1361.996417</td>\n",
       "      <td>579.032347</td>\n",
       "      <td>1384.297239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>6/2001</td>\n",
       "      <td>1424.133449</td>\n",
       "      <td>948.659166</td>\n",
       "      <td>1359.490711</td>\n",
       "      <td>578.785627</td>\n",
       "      <td>1380.271050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>5/2001</td>\n",
       "      <td>1426.330478</td>\n",
       "      <td>950.624340</td>\n",
       "      <td>1360.724916</td>\n",
       "      <td>578.907151</td>\n",
       "      <td>1382.254180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>4/2001</td>\n",
       "      <td>1416.682719</td>\n",
       "      <td>941.994717</td>\n",
       "      <td>1355.305181</td>\n",
       "      <td>578.373507</td>\n",
       "      <td>1373.545709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3/2001</td>\n",
       "      <td>1396.255778</td>\n",
       "      <td>923.723448</td>\n",
       "      <td>1343.830123</td>\n",
       "      <td>577.243638</td>\n",
       "      <td>1355.107496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2/2001</td>\n",
       "      <td>1415.925630</td>\n",
       "      <td>941.317524</td>\n",
       "      <td>1354.879878</td>\n",
       "      <td>578.331630</td>\n",
       "      <td>1372.862328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1/2001</td>\n",
       "      <td>1444.029217</td>\n",
       "      <td>966.455316</td>\n",
       "      <td>1370.667376</td>\n",
       "      <td>579.886116</td>\n",
       "      <td>1398.229803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>12/2000</td>\n",
       "      <td>1411.654170</td>\n",
       "      <td>937.496836</td>\n",
       "      <td>1352.480339</td>\n",
       "      <td>578.095364</td>\n",
       "      <td>1369.006730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>11/2000</td>\n",
       "      <td>1400.479870</td>\n",
       "      <td>927.501768</td>\n",
       "      <td>1346.203053</td>\n",
       "      <td>577.477284</td>\n",
       "      <td>1358.920339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10/2000</td>\n",
       "      <td>1425.718654</td>\n",
       "      <td>950.077083</td>\n",
       "      <td>1360.381217</td>\n",
       "      <td>578.873309</td>\n",
       "      <td>1381.701923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  morningstar msci emerging markets   s&p 500 pr  \\\n",
       "0     9/2020                        3404.811278  2720.314412   \n",
       "1     8/2020                        3454.425614  2764.692906   \n",
       "2     7/2020                        3400.050169  2716.055747   \n",
       "3     6/2020                        3284.010200  2612.261573   \n",
       "4     5/2020                        3213.081920  2548.818413   \n",
       "5     4/2020                        3145.379162  2488.260384   \n",
       "6     3/2020                        2996.308271  2354.921068   \n",
       "7     2/2020                        3207.277138  2543.626215   \n",
       "8     1/2020                        3283.021423  2611.377142   \n",
       "9    12/2019                        3259.265705  2590.128385   \n",
       "10   11/2019                        3215.003944  2550.537605   \n",
       "11   10/2019                        3195.010168  2532.653788   \n",
       "12    9/2019                        3159.315824  2500.726298   \n",
       "13    8/2019                        3136.662340  2480.463455   \n",
       "14    7/2019                        3126.567300  2471.433753   \n",
       "15    6/2019                        3118.254473  2463.998186   \n",
       "16    5/2019                        3028.248430  2383.490555   \n",
       "17    4/2019                        3076.436776  2426.593545   \n",
       "18    3/2019                        3037.530501  2391.793082   \n",
       "19    2/2019                        2986.586204  2346.224979   \n",
       "20    1/2019                        2950.721241  2314.144875   \n",
       "21   12/2018                        2857.015488  2230.327969   \n",
       "22   11/2018                        2909.174823  2276.982885   \n",
       "23   10/2018                        2884.627044  2255.025654   \n",
       "24    9/2018                        2980.828000  2341.074443   \n",
       "25    8/2018                        2993.129289  2352.077566   \n",
       "26    7/2018                        2993.399011  2352.318824   \n",
       "27    6/2018                        2972.661720  2333.769957   \n",
       "28    5/2018                        2987.957266  2347.451352   \n",
       "29    4/2018                        2985.793843  2345.516237   \n",
       "..       ...                                ...          ...   \n",
       "210   3/2003                        1452.403904   973.946216   \n",
       "211   2/2003                        1451.898245   973.493920   \n",
       "212   1/2003                        1442.777974   965.336118   \n",
       "213  12/2002                        1445.203370   967.505560   \n",
       "214  11/2002                        1444.770537   967.118405   \n",
       "215  10/2002                        1424.820785   949.273967   \n",
       "216   9/2002                        1411.472004   937.333893   \n",
       "217   8/2002                        1426.745948   950.995965   \n",
       "218   7/2002                        1411.615104   937.461892   \n",
       "219   6/2002                        1431.154335   954.939132   \n",
       "220   5/2002                        1453.811922   975.205644   \n",
       "221   4/2002                        1451.458985   973.101015   \n",
       "222   3/2002                        1456.531671   977.638376   \n",
       "223   2/2002                        1448.956022   970.862192   \n",
       "224   1/2002                        1444.698180   967.053683   \n",
       "225  12/2001                        1438.065617   961.121060   \n",
       "226  11/2001                        1432.794254   956.405988   \n",
       "227  10/2001                        1410.569433   936.526571   \n",
       "228   9/2001                        1388.279822   916.589201   \n",
       "229   8/2001                        1418.344203   943.480864   \n",
       "230   7/2001                        1428.593899   952.648900   \n",
       "231   6/2001                        1424.133449   948.659166   \n",
       "232   5/2001                        1426.330478   950.624340   \n",
       "233   4/2001                        1416.682719   941.994717   \n",
       "234   3/2001                        1396.255778   923.723448   \n",
       "235   2/2001                        1415.925630   941.317524   \n",
       "236   1/2001                        1444.029217   966.455316   \n",
       "237  12/2000                        1411.654170   937.496836   \n",
       "238  11/2000                        1400.479870   927.501768   \n",
       "239  10/2000                        1425.718654   950.077083   \n",
       "\n",
       "     bbgbarc us treasury tr usd(1972)  \\\n",
       "0                         2472.158183   \n",
       "1                         2500.029580   \n",
       "2                         2469.483578   \n",
       "3                         2404.296854   \n",
       "4                         2364.452115   \n",
       "5                         2326.419350   \n",
       "6                         2242.677143   \n",
       "7                         2361.191216   \n",
       "8                         2403.741397   \n",
       "9                         2390.396363   \n",
       "10                        2365.531834   \n",
       "11                        2354.300111   \n",
       "12                        2334.248422   \n",
       "13                        2321.522579   \n",
       "14                        2315.851580   \n",
       "15                        2311.181758   \n",
       "16                        2260.619877   \n",
       "17                        2287.690209   \n",
       "18                        2265.834183   \n",
       "19                        2237.215666   \n",
       "20                        2217.068130   \n",
       "21                        2164.427896   \n",
       "22                        2193.728974   \n",
       "23                        2179.938990   \n",
       "24                        2233.980931   \n",
       "25                        2240.891315   \n",
       "26                        2241.042834   \n",
       "27                        2229.393434   \n",
       "28                        2237.985874   \n",
       "29                        2236.770548   \n",
       "..                                ...   \n",
       "210                       1375.371948   \n",
       "211                       1375.087889   \n",
       "212                       1369.964477   \n",
       "213                       1371.326970   \n",
       "214                       1371.083821   \n",
       "215                       1359.876829   \n",
       "216                       1352.378005   \n",
       "217                       1360.958310   \n",
       "218                       1352.458393   \n",
       "219                       1363.434770   \n",
       "220                       1376.162918   \n",
       "221                       1374.841130   \n",
       "222                       1377.690767   \n",
       "223                       1373.435063   \n",
       "224                       1371.043173   \n",
       "225                       1367.317258   \n",
       "226                       1364.356012   \n",
       "227                       1351.870976   \n",
       "228                       1339.349542   \n",
       "229                       1356.238538   \n",
       "230                       1361.996417   \n",
       "231                       1359.490711   \n",
       "232                       1360.724916   \n",
       "233                       1355.305181   \n",
       "234                       1343.830123   \n",
       "235                       1354.879878   \n",
       "236                       1370.667376   \n",
       "237                       1352.480339   \n",
       "238                       1346.203053   \n",
       "239                       1360.381217   \n",
       "\n",
       "     libor 3 mon interbank eurodollar inv tr  bbgbarc us credit tr usd  \n",
       "0                                 688.342291               3168.113801  \n",
       "1                                 691.086594               3212.897777  \n",
       "2                                 688.078941               3163.816224  \n",
       "3                                 681.660455               3059.073689  \n",
       "4                                 677.737220               2995.050853  \n",
       "5                                 673.992397               2933.939509  \n",
       "6                                 665.746881               2799.381880  \n",
       "7                                 677.416142               2989.811214  \n",
       "8                                 681.605764               3058.181177  \n",
       "9                                 680.291770               3036.738272  \n",
       "10                                677.843532               2996.785753  \n",
       "11                                676.737622               2978.738533  \n",
       "12                                674.763271               2946.519323  \n",
       "13                                673.510246               2926.071340  \n",
       "14                                672.951862               2916.959134  \n",
       "15                                672.492057               2909.455629  \n",
       "16                                667.513578               2828.212405  \n",
       "17                                670.179006               2871.709224  \n",
       "18                                668.026995               2836.590791  \n",
       "19                                665.209127               2790.606335  \n",
       "20                                663.225339               2758.233118  \n",
       "21                                658.042220               2673.650381  \n",
       "22                                660.927294               2720.731581  \n",
       "23                                659.569490               2698.573728  \n",
       "24                                664.890626               2785.408739  \n",
       "25                                665.571043               2796.512397  \n",
       "26                                665.585962               2796.755860  \n",
       "27                                664.438926               2778.037513  \n",
       "28                                665.284965               2791.843913  \n",
       "29                                665.165300               2789.891117  \n",
       "..                                       ...                       ...  \n",
       "210                               580.349343               1405.789146  \n",
       "211                               580.321373               1405.332718  \n",
       "212                               579.816906               1397.100379  \n",
       "213                               579.951062               1399.289643  \n",
       "214                               579.927120               1398.898950  \n",
       "215                               578.823646               1380.891468  \n",
       "216                               578.085288               1368.842299  \n",
       "217                               578.930132               1382.629201  \n",
       "218                               578.093204               1368.971467  \n",
       "219                               579.173971               1386.608396  \n",
       "220                               580.427224               1407.060082  \n",
       "221                               580.297077               1404.936223  \n",
       "222                               580.577661               1409.515042  \n",
       "223                               580.158631               1402.676944  \n",
       "224                               579.923118               1398.833637  \n",
       "225                               579.556253               1392.846808  \n",
       "226                               579.264680               1388.088655  \n",
       "227                               578.035365               1368.027601  \n",
       "228                               576.802466               1347.908064  \n",
       "229                               578.465408               1375.045434  \n",
       "230                               579.032347               1384.297239  \n",
       "231                               578.785627               1380.271050  \n",
       "232                               578.907151               1382.254180  \n",
       "233                               578.373507               1373.545709  \n",
       "234                               577.243638               1355.107496  \n",
       "235                               578.331630               1372.862328  \n",
       "236                               579.886116               1398.229803  \n",
       "237                               578.095364               1369.006730  \n",
       "238                               577.477284               1358.920339  \n",
       "239                               578.873309               1381.701923  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = PCARiskScenarioSQL(scenario_name = 'PCA', risk_factors = factors, username = username, password = password)\n",
    "x.set_up(data_path = {'index': {'morningstar msci emerging markets': 'Emerging Markets.csv',\n",
    "                                                      's&p 500 pr': 'S&P 500.csv',\n",
    "                                                      'bbgbarc us treasury tr usd(1972)': 'BBgBarc US Treasury.csv',\n",
    "                                                      'libor 3 mon interbank eurodollar inv tr': 'LIBOR 3 Mon Interbank Eurodollar Inv.csv',\n",
    "                                                      'bbgbarc us credit tr usd': 'BBgBarc US Credit.csv'}}, shocks = {'pc_1': -0.2},factor_choice = 'pc')\n",
    "x.update_raw_data()\n",
    "x.generate_scenario()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sythetic Return Series Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticReturnSeriesGenerator(LassoRegressionRiskGenerator):\n",
    "    \"\"\"Generate synthetic return series using RBSA\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__\n",
    "    \n",
    "    def synthetic_return_series_generation(self):\n",
    "        \"\"\"Impletment Lasso Regression to make up return series of funds which have shorter historical return records than indexes.\n",
    "           Inputs are return series of funds and indexes.\n",
    "           Outputs are synthetic return series of funds which are suitable to use RBSA to generate synthetic return series\n",
    "        \"\"\"\n",
    "        X, Y = self._factors_data.to_numpy()[:,1:], self._assets_data.to_numpy()[:,1:]\n",
    "        self._asset_data_synthetic = self._assets_data.copy()\n",
    "        alpha = self._hyperparameters.get('alpha')\n",
    "        max_iter = self._hyperparameters.get('max_iter')\n",
    "        for i in range(Y.shape[1]):\n",
    "            if sum(np.isnan(Y[:,i])) == 0:\n",
    "                continue\n",
    "            elif sum(np.isnan(Y[:,i])[:36]) > 0: # check whether the most recent 36 months of returns exist\n",
    "                print('Fund ' + self._assets_data.columns[i+1] +' cannot use RBSA to generate synthetic return series') \n",
    "                self._asset_data_synthetic.loc[:, i+1] = np.nan\n",
    "            else:\n",
    "                idx = ~np.isnan(Y[:,i]) #the index that the return series exists\n",
    "                lasso = Lasso(alpha = alpha, max_iter = max_iter, fit_intercept=False)\n",
    "                lasso.fit(X[idx], Y[idx, i])\n",
    "                beta = lasso.coef_\n",
    "                print(lasso.score(X[idx], Y[idx, i]))\n",
    "                if lasso.score(X[idx], Y[idx, i]) >= 0.7: #check whether LASSO regression achieves the threshold to be used to create a synthetic return history\n",
    "                    weight = beta/np.sum(beta)\n",
    "                    synthetic_rtn = np.dot(X, weight) + np.random.normal(size = len(X)) # add independent standard normal noise\n",
    "                    self._asset_data_synthetic.loc[~idx, i+1] = synthetic_rtn[~idx]\n",
    "                else:\n",
    "                    self._asset_data_synthetic.loc[:, i+1] = np.nan\n",
    "                    print('Fund ' + self._assets_data.columns[i+1] +' cannot use RBSA to generate synthetic return series') \n",
    "        \n",
    "        self._asset_data_synthetic.dropna(axis = 1, inplace = True)\n",
    "        return self._asset_data_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SyntheticReturnSeriesGenerator()\n",
    "x.set_up(risk_factors = factors, hyperparameters = {'alpha': 0.6, 'max_iter': 100000}, data_path = {'index': 'Index.csv', 'fund': '../data/syn_rtn_sample_fund.csv'})\n",
    "x.load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025303240494961576\n",
      "Fund AAAAX cannot use RBSA to generate synthetic return series\n",
      "Fund AAABX cannot use RBSA to generate synthetic return series\n",
      "Fund AAACX cannot use RBSA to generate synthetic return series\n",
      "Fund AAADX cannot use RBSA to generate synthetic return series\n",
      "Fund AAAEX cannot use RBSA to generate synthetic return series\n",
      "0.05494484687615819\n",
      "Fund AAAGX cannot use RBSA to generate synthetic return series\n",
      "0.004197575267383402\n",
      "Fund AAANX cannot use RBSA to generate synthetic return series\n",
      "0.0020486686981885383\n",
      "Fund AAAPX cannot use RBSA to generate synthetic return series\n",
      "0.008989358398208247\n",
      "Fund AAAQX cannot use RBSA to generate synthetic return series\n",
      "0.005553776919374087\n",
      "Fund AAARX cannot use RBSA to generate synthetic return series\n",
      "0.0029727270991414256\n",
      "Fund AAASX cannot use RBSA to generate synthetic return series\n",
      "0.005953371004166819\n",
      "Fund AAATX cannot use RBSA to generate synthetic return series\n",
      "Fund AAAU cannot use RBSA to generate synthetic return series\n",
      "0.009532267218249513\n",
      "Fund AAAUX cannot use RBSA to generate synthetic return series\n",
      "0.017647899226778008\n",
      "Fund AAAVX cannot use RBSA to generate synthetic return series\n",
      "0.04560501137338824\n",
      "Fund AAAWX cannot use RBSA to generate synthetic return series\n",
      "Fund AAAYX cannot use RBSA to generate synthetic return series\n",
      "0.003211039795170567\n",
      "Fund AAAZX cannot use RBSA to generate synthetic return series\n",
      "0.006387829882193108\n",
      "Fund AABAX cannot use RBSA to generate synthetic return series\n",
      "Fund AABBX cannot use RBSA to generate synthetic return series\n"
     ]
    }
   ],
   "source": [
    "syn_rtn = x.synthetic_return_series_generation()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stress Test - HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
